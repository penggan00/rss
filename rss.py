import asyncio
import aiohttp
import logging
import re
import os
import hashlib
import pytz
import fcntl
import time
import signal
import sys
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
from feedparser import parse
from telegram import Bot
from telegram.error import BadRequest
from urllib.parse import urlparse
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from md2tgmd import escape
from tencentcloud.common import credential
from tencentcloud.common.profile.client_profile import ClientProfile
from tencentcloud.common.profile.http_profile import HttpProfile
from tencentcloud.tmt.v20180321 import tmt_client, models
from tencentcloud.common.exception.tencent_cloud_sdk_exception import TencentCloudSDKException

# ========== ç¯å¢ƒåŠ è½½ ==========
load_dotenv()
BASE_DIR = Path(__file__).resolve().parent
LOCK_FILE = BASE_DIR / "rss.lock"   # é”æ–‡ä»¶è·¯å¾„
DATABASE_FILE = BASE_DIR / "rss.db" # SQLite æ•°æ®åº“æ–‡ä»¶è·¯å¾„

logging.basicConfig(
    filename=BASE_DIR / "rss.log",  # æ—¥å¿—æ–‡ä»¶è·¯å¾„
    level=logging.WARNING,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    encoding="utf-8"
)
logger = logging.getLogger(__name__) # å…¨å±€æ—¥å¿—è®°å½•å™¨

TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID").split(",")  # Telegram Chat IDs
TENCENTCLOUD_SECRET_ID = os.getenv("TENCENTCLOUD_SECRET_ID") # è…¾è®¯äº‘ Secret ID
TENCENTCLOUD_SECRET_KEY = os.getenv("TENCENTCLOUD_SECRET_KEY") # è…¾è®¯äº‘ Secret Key
TENCENT_REGION = os.getenv("TENCENT_REGION", "na-siliconvalley") # è…¾è®¯äº‘åŒºåŸŸ
TENCENT_SECRET_ID = os.getenv("TENCENT_SECRET_ID") # è…¾è®¯ Secret ID
TENCENT_SECRET_KEY = os.getenv("TENCENT_SECRET_KEY")  # è…¾è®¯ Secret Key
semaphore = asyncio.Semaphore(2)                     # æ§åˆ¶å¹¶å‘æ•° 
BACKUP_DOMAINS_STR = os.getenv("BACKUP_DOMAINS", "") # å¤‡ç”¨åŸŸåï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”
BACKUP_DOMAINS = [domain.strip() for domain in BACKUP_DOMAINS_STR.split(",") if domain.strip()] # å¤‡ç”¨åŸŸååˆ—è¡¨
# å®šä¹‰æ—¶é—´é—´éš” (ç§’)  600ç§’ = 10åˆ†é’Ÿ   1200ç§’ = 20åˆ†é’Ÿ   1800ç§’ = 30åˆ†é’Ÿ  3600ç§’ = 1å°æ—¶   7200ç§’ = 2å°æ—¶   10800ç§’ = 3å°æ—¶
RSS_GROUPS = [ # RSS ç»„é…ç½®åˆ—è¡¨
    # ================== å›½é™…æ–°é—»ç»„ ==================False: å…³é—­ / True: å¼€å¯
    {
        "name": "å›½é™…æ–°é—»",
        "urls": [
            'https://feeds.bbci.co.uk/news/world/rss.xml',  # BBC
            'https://www3.nhk.or.jp/rss/news/cat6.xml',     # NHK
       #     'https://www.cnbc.com/id/100003114/device/rss/rss.html',  # CNBC
         #   'https://feeds.a.dj.com/rss/RSSWorldNews.xml',  # åå°”è¡—æ—¥æŠ¥
        #    'https://feeds.content.dowjones.io/public/rss/RSSWorldNews',   # åå°”è¡—æ—¥æŠ¥
        #    'https://feeds.content.dowjones.io/public/rss/socialeconomyfeed',
           'https://www.aljazeera.com/xml/rss/all.xml',    # åŠå²›ç”µè§†å°
        #    'https://www.ft.com/?format=rss',                 # é‡‘èæ—¶æŠ¥
       #     'https://www3.nhk.or.jp/rss/news/cat5.xml',  # NHK å•†ä¸š
       #     'http://rss.cnn.com/rss/cnn_topstories.rss',   # cnn
       #     'https://www.theguardian.com/world/rss',     # å«æŠ¥
      #      'https://www.theverge.com/rss/index.xml',   # The Verge:
        ],
        "group_key": "RSS_FEEDS",
        "interval": 3590,      # 60åˆ†é’Ÿ 
        "history_days": 30,     # æ–°å¢ï¼Œä¿ç•™30å¤©
        "bot_token": os.getenv("RSS_TWO"),    # Telegram Bot Token
        "processor": {
            "translate": True,       #ç¿»è¯‘å¼€
            "header_template": "ğŸ“¢ *{source}*\n",  # æ–°å¢æ ‡é¢˜æ¨¡æ¿ â˜…
            "template": "*{subject}*\n[more]({url})",
            "preview": False,         # ç¦æ­¢é¢„è§ˆ
            "show_count": False        # âœ…æ–°å¢
        }
    },

    # ================== å›½é™…æ–°é—»ä¸­æ–‡ç»„ ==================False: å…³é—­ / True: å¼€å¯
    {
        "name": "å›½é™…æ–°é—»ä¸­æ–‡",
        "urls": [
            'https://www.ftchinese.com/rss/news',   # ftä¸­æ–‡ç½‘
        ],
        "group_key": "RSS_FEEDS_INTERNATIONAL",
        "interval": 10790,      # 3å°æ—¶
        "history_days": 30,     # æ–°å¢ï¼Œä¿ç•™30å¤©
        "bot_token": os.getenv("RSS_TWO"),    # Telegram Bot Token
        "processor": {
            "translate": False,       #ç¿»è¯‘ False: å…³é—­ / True: å¼€å¯
            "header_template": "ğŸ“¢ *{source}*\n",  # æ–°å¢æ ‡é¢˜æ¨¡æ¿ â˜…
            "template": "*{subject}*\n[more]({url})",
            "preview": False,         # ç¦æ­¢é¢„è§ˆ
            "show_count": False        # âœ…æ–°å¢
        }
    },

    # ================== å¿«è®¯ç»„ ==================
    {
        "name": "å¿«è®¯",
        "urls": [
         #   'https://rsshub.app/10jqka/realtimenews', #åŒèŠ±é¡ºè´¢ç»
            'https://36kr.com/feed-newsflash',  # 36æ°ªå¿«è®¯
        #    'https://36kr.com/feed',  # 36æ°ªç»¼åˆ
            
        ],
        "group_key": "FOURTH_RSS_FEEDS",
        "interval": 960,       # 20åˆ†é’Ÿ 
        "history_days": 5,     # æ–°å¢ï¼Œä¿ç•™30å¤©
        "bot_token": os.getenv("RSS_LINDA"),   # Telegram Bot Token
        "processor": {
            "translate": False,     #ç¿»è¯‘å¼€å…³
            "header_template": "ğŸ“¢ *{source}*\n",  # æ–°å¢æ ‡é¢˜æ¨¡æ¿ â˜…
            "template": "*{subject}*\n[more]({url})",
            "preview": False,            # ç¦æ­¢é¢„è§ˆ
            "show_count": False          #è®¡æ•°
        }
    },
    # ================== å¿«è®¯ç»„ ==================
    {
        "name": "å¿«è®¯",
        "urls": [
            'https://rsshub.app/10jqka/realtimenews', #åŒèŠ±é¡ºè´¢ç»
         #   'https://36kr.com/feed-newsflash',  # 36æ°ªå¿«è®¯
        #    'https://36kr.com/feed',  # 36æ°ªç»¼åˆ
            
        ],
        "group_key": "TOURTH_RSS_FEEDS",
        "interval": 650,       # 15åˆ†é’Ÿ
        "history_days": 5,     # æ–°å¢ï¼Œä¿ç•™30å¤©
        "bot_token": os.getenv("TONGHUASHUN_RSS"),  #   Telegram Bot Token
        "processor": {
            "translate": False,     #ç¿»è¯‘å¼€å…³
            "header_template": "ğŸ“¢ *{source}*\n",  # æ–°å¢æ ‡é¢˜æ¨¡æ¿ â˜…
            "template": "*{subject}*\n[more]({url})",
            "filter": {
                "enable": False,  # è¿‡æ»¤å¼€å…³     False: å…³é—­ / True: å¼€å¯
                "mode": "allow",  # allowæ¨¡å¼ï¼šåŒ…å«å…³é”®è¯æ‰å‘é€ / blockæ¨¡å¼ï¼šåŒ…å«å…³é”®è¯ä¸å‘é€
                "keywords": ["å…", "cf", "cl", "é»‘", "ä½", "å°", "å¡", "å¹´", "bug", "ç™½", "github",  "èŠ‚",  "é—ª",  "cc", "rn", "åŠ¨", "cloudcone", "docker", "æŠ˜"]  # æœ¬ç»„å…³é”®è¯åˆ—è¡¨
            },
            "preview": False,            # ç¦æ­¢é¢„è§ˆ
            "show_count": False          #è®¡æ•°
        }
    },

    # ================== æ–°æµªåšå®¢ ==================
    {
        "name": "ç¤¾äº¤åª’ä½“",
        "urls": [
            'https://rsshub.app/weibo/user/3194547262',  # æ±Ÿè¥¿é«˜é€Ÿ
            'https://rsshub.app/weibo/user/1699432410',  # æ–°åç¤¾
        #    'https://rsshub.app/weibo/user/2656274875',  # å¤®è§†æ–°é—»
            'https://rsshub.app/weibo/user/2716786595',  # èšèä¹¡
            'https://rsshub.app/weibo/user/1891035762',  # äº¤è­¦
       #     'https://rsshub.app/weibo/user/3917937138',  # å‘å¸ƒ
        #    'https://rsshub.app/weibo/user/3213094623',  # é‚®æ”¿
        #    'https://rsshub.app/weibo/user/2818241427',  # å†’é™©å²›

        ],
        "group_key": "FIFTH_RSSSA_FEEDS",
        "interval": 10790,    # 3å°æ—¶
        "history_days": 300,     # æ–°å¢ï¼Œä¿ç•™300å¤©
        "bot_token": os.getenv("RRSS_LINDA"),  # Telegram Bot Token
        "processor": {
            "translate": False,     #ç¿»è¯‘å…³
            "header_template": "ğŸ“¢ *{source}*\n",  # æ–°å¢æ ‡é¢˜æ¨¡æ¿ â˜…
         #   "template": "*{subject}*\nğŸ”— {url}",
            "template": "*{subject}*\n[more]({url})",
            "preview": False,        # ç¦æ­¢é¢„è§ˆ
            "show_count": False     #è®¡æ•°
        }
    },

    # ================== æŠ€æœ¯è®ºå›ç»„ ==================
    {
        "name": "æŠ€æœ¯è®ºå›",
        "urls": [
            'https://rss.nodeseek.com',  # Nodeseek  
        ],
        "group_key": "FIFTH_RSS_RSS_SAN", 
        "interval": 240,       # 4åˆ†é’Ÿ 
        "history_days": 3,     # æ–°å¢ï¼Œä¿ç•™30å¤©
        "bot_token": os.getenv("RSS_SAN"), # Telegram Bot Token
        "processor": {
            "translate": False,                  #ç¿»è¯‘å…³
            "header_template": "ğŸ“¢ *{source}*\n",  # æ–°å¢æ ‡é¢˜æ¨¡æ¿ â˜…
            "template": "*{subject}*\n[more]({url})", 
            "filter": {
                "enable": False,  # è¿‡æ»¤å¼€å…³     False: å…³é—­ / True: å¼€å¯
                "mode": "allow",  # allowæ¨¡å¼ï¼šåŒ…å«å…³é”®è¯æ‰å‘é€ / blockæ¨¡å¼ï¼šåŒ…å«å…³é”®è¯ä¸å‘é€
                "keywords": ["å…", "cf", "cl", "é»‘", "ä½", "å°", "å¡", "å¹´", "bug", "ç™½", "github",  "èŠ‚",  "é—ª",  "cc", "rn", "åŠ¨", "cloudcone", "docker", "æŠ˜"]  # æœ¬ç»„å…³é”®è¯åˆ—è¡¨
            },
            "preview": False,              # ç¦æ­¢é¢„è§ˆ
            "show_count": False               #è®¡æ•°
        }
    },
    {
        "name": "ç¤¾äº¤åª’ä½“",
        "urls": [
        #    'https://lowendspirit.com/discussions/feed.rss', # lowendspirit
       #     'https://lowendtalk.com/discussions/feed.rss',   # lowendtalk
     
        ],
        "group_key": "FIFTHHHH_RSSS_FEEDS",
        "interval": 7190,      # 1å°æ—¶56åˆ†é’Ÿ
        "history_days": 30,     # æ–°å¢ï¼Œä¿ç•™30å¤©
        "bot_token": os.getenv("RSS_SAN"),  # Telegram Bot Token
        "processor": {
            "translate": True,                     #ç¿»è¯‘å¼€
            "header_template": "ğŸ“¢ *{source}*\n",  # æ–°å¢æ ‡é¢˜æ¨¡æ¿ â˜…
         #   "template": "*{subject}*\nğŸ”— {url}",
            "template": "*{subject}*\n[more]({url})",  #æ–°å¢
            "preview": False,       # ç¦æ­¢é¢„è§ˆ
            "show_count": False     #è®¡æ•°
        }
    },
    # ================== YouTubeé¢‘é“ç»„ ==================
    {
        "name": "YouTubeé¢‘é“",
        "urls": [
         #   'https://blog.090227.xyz/atom.xml',
         #   'https://www.freedidi.com/feed',
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCvijahEyGtvMpmMHBu4FS2w', # é›¶åº¦è§£è¯´
            'https://www.youtube.com/feeds/videos.xml?channel_id=UC96OvMh0Mb_3NmuE8Dpu7Gg', # ææœºé›¶è·ç¦»
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCQoagx4VHBw3HkAyzvKEEBA', # ç§‘æŠ€å…±äº«
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCbCCUH8S3yhlm7__rhxR2QQ', # ä¸è‰¯æ—
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCMtXiCoKFrc2ovAGc1eywDg', # ä¸€ä¼‘
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCii04BCvYIdQvshrdNDAcww', # æ‚Ÿç©ºçš„æ—¥å¸¸
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCJMEiNh1HvpopPU3n9vJsMQ', # ç†ç§‘ç”·å£«
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCYjB6uufPeHSwuHs8wovLjg', # ä¸­æŒ‡é€š
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCSs4A6HYKmHA2MG_0z-F0xw', # ææ°¸ä¹è€å¸ˆ
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCZDgXi7VpKhBJxsPuZcBpgA', # å¯æ©KeEn
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCxukdnZiXnTFvjF5B5dvJ5w', # ç”¬å“¥ä¾ƒä¾ƒä¾ƒygkkk
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCUfT9BAofYBKUTiEVrgYGZw', # ç§‘æŠ€åˆ†äº«
            'https://www.youtube.com/feeds/videos.xml?channel_id=UC51FT5EeNPiiQzatlA2RlRA', # ä¹Œå®¢wuke
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCDD8WJ7Il3zWBgEYBUtc9xQ', # jack stone
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCWurUlxgm7YJPPggDz9YJjw', # ä¸€ç“¶å¥¶æ²¹
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCvENMyIFurJi_SrnbnbyiZw', # é…·å‹ç¤¾
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCmhbF9emhHa-oZPiBfcLFaQ', # WenWeekly
            'https://www.youtube.com/feeds/videos.xml?channel_id=UC3BNSKOaphlEoK4L7QTlpbA', # ä¸­å¤–è§‚å¯Ÿ
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCXk0rwHPG9eGV8SaF2p8KUQ', # çƒé´‰ç¬‘ç¬‘
                    # ... å…¶ä»–YouTubeé¢‘é“ï¼ˆå…±18ä¸ªï¼‰
        ],
        "group_key": "YOUTUBE_RSSS_FEEDS", # YouTubeé¢‘é“
        "interval": 3590,      # 60åˆ†é’Ÿ
        "history_days": 360,     # æ–°å¢ï¼Œä¿ç•™30å¤©
        "bot_token": os.getenv("RSS_TOKEN"),   # Telegram Bot Token
        "processor": {
            "translate": False,                    #ç¿»è¯‘å…³
            "header_template": "ğŸ“¢ *{source}*\n",  # æ–°å¢æ ‡é¢˜æ¨¡æ¿ â˜…
            "template": "*{subject}*\n[more]({url})",
            "preview": True,                # é¢„è§ˆ
            "show_count": False               #è®¡æ•°
        }
    },

    # ================== ä¸­æ–‡YouTubeç»„ ==================
    {
        "name": "ä¸­æ–‡YouTube",
        "urls": [
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCUNciDq-y6I6lEQPeoP-R5A', # è‹æ’è§‚å¯Ÿ
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCXkOTZJ743JgVhJWmNV8F3Q', # å¯’åœ‹äºº
            'https://www.youtube.com/feeds/videos.xml?channel_id=UC2r2LPbOUssIa02EbOIm7NA', # æ˜Ÿçƒç†±é»
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCF-Q1Zwyn9681F7du8DMAWg', # è¬å®—æ¡“-è€è¬ä¾†äº†
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCSYBgX9pWGiUAcBxjnj6JCQ', # éƒ­æ­£äº®é »é“
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCNiJNzSkfumLB7bYtXcIEmg', # çœŸçš„å¾ˆåšé€š
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCN0eCImZY6_OiJbo8cy5bLw', # å±ˆæ©ŸTV
         #   'https://www.youtube.com/feeds/videos.xml?channel_id=UCb3TZ4SD_Ys3j4z0-8o6auA', # BBC News ä¸­æ–‡
       #     'https://www.youtube.com/feeds/videos.xml?channel_id=UCiwt1aanVMoPYUt_CQYCPQg', # å…¨çƒå¤§è¦–é‡
            'https://www.youtube.com/feeds/videos.xml?channel_id=UC000Jn3HGeQSwBuX_cLDK8Q', # æˆ‘æ˜¯æŸ³å‚‘å…‹
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCQFEBaHCJrHu2hzDA_69WQg', # å›½æ¼«è¯´
            'https://www.youtube.com/feeds/videos.xml?channel_id=UChJ8YKw6E1rjFHVS9vovrZw', # BNE TV - æ–°è¥¿å…°ä¸­æ–‡å›½é™…é¢‘é“
          #  'https://www.youtube.com/feeds/videos.xml?channel_id=UCJncdiH3BQUBgCroBmhsUhQ', # è§‚å¯Ÿè€…ç½‘
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCSYBgX9pWGiUAcBxjnj6JCQ', # éƒ­æ­£äº®é »é“
        # å½±è§†
            'https://www.youtube.com/feeds/videos.xml?channel_id=UC7Xeh7thVIgs_qfTlwC-dag', # Marc TV
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCCD14H7fJQl3UZNWhYMG3Mg', # æ¸©åŸé²¤
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCQO2T82PiHCYbqmCQ6QO6lw', # æœˆäº®èªª
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCHW6W9g2TJL2_Lf7GfoI5kg', # ç”µå½±æ”¾æ˜ å…
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCi2GvcaxZCN-61a0co8Smnw', # é¤¨é•·
   # bilibili
       #     'https://rsshub.app/bilibili/user/video/271034954', #æ— é™æµ·å­
        #    'https://rsshub.app/bilibili/user/video/10720688', #ä¹Œå®¢wuke
         #   'https://rsshub.app/bilibili/user/video/33683045', #å¼ å¬å¿ 
        #    'https://rsshub.app/bilibili/user/video/9458053', #ææ°¸ä¹
         #   'https://rsshub.app/bilibili/user/video/456664753', #å¤®è§†æ–°é—»
          #  'https://rsshub.app/bilibili/user/video/95832115', #æ±æœµæ›¼
          #  'https://rsshub.app/bilibili/user/video/3546741104183937', #æ²¹ç®¡ç²¾é¸å­—å¹•ç»„
          #  'https://rsshub.app/bilibili/user/video/52165725', #ç‹éªAlbert
        ],
        "group_key": "FIFTH_RSS_YOUTUBE", # YouTubeé¢‘é“
        "interval": 35990,     # 10å°æ—¶
        "history_days": 360,     # æ–°å¢ï¼Œä¿ç•™300å¤©
        "bot_token": os.getenv("YOUTUBE_RSS"),    # Telegram Bot Token
        "processor": {
        "translate": False,                    #ç¿»è¯‘å…³
        "header_template": "ğŸ“¢ *{source}*\n",  # æ–°å¢æ ‡é¢˜æ¨¡æ¿ â˜…
    #   "template": "*{subject}*\nğŸ”— {url}",
        "template": "*{subject}*\n[more]({url})",
        "preview": True,                       # é¢„è§ˆ
        "show_count": False                    #è®¡æ•°
    }
    },
    # ================== ç¤¾äº¤åª’ä½“ç»„+ç¿»è¯‘é¢„è§ˆ ==================
    {
        "name": "ç¤¾äº¤åª’ä½“",
        "urls": [
        #    'https://rsshub.app/twitter/media/clawcloud43609', # claw.cloud
         #   'https://rsshub.app/twitter/media/ElonMuskAOC',   # Elon Musk
        #    'https://rsshub.app/twitter/media/elonmusk',   # Elon Musk
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCQeRaTukNYft1_6AZPACnog',  # Asmongold
        ],
        "group_key": "FIFTH_RSS_FEEDS",   # YouTubeé¢‘é“
        "interval": 17990,    # 5å°æ—¶
        "history_days": 300,     # æ–°å¢ï¼Œä¿ç•™30å¤©
        "bot_token": os.getenv("YOUTUBE_RSS"),  # Telegram Bot Token
        "processor": {
            "translate": True,          #ç¿»è¯‘å¼€
            "header_template": "ğŸ“¢ *{source}*\n",  # æ–°å¢æ ‡é¢˜æ¨¡æ¿ â˜…
         #   "template": "*{subject}*\nğŸ”— {url}",
            "template": "*{subject}*\n[more]({url})",
            "preview": True,        # é¢„è§ˆ
            "show_count": False     #è®¡æ•°
        }
    },
    # ================== ä¸­æ–‡åª’ä½“ç»„ ==================
    {
        "name": "ä¸­æ–‡åª’ä½“", 
        "urls": [
            'https://rsshub.app/guancha/headline',
            'https://rsshub.app/guancha',
            'https://rsshub.app/zaobao/znews/china',
        ],
        "group_key": "THIRD_RSS_FEEDS",
        "interval": 7190,      # 2å°æ—¶
        "history_days": 30,     # æ–°å¢ï¼Œä¿ç•™30å¤©
        "bot_token": os.getenv("RSS_LINDA_YOUTUBE"), # Telegram Bot Token
        "processor": {
            "translate": False,                        #ç¿»è¯‘å¼€å…³
            "header_template": "ğŸ“¢ *{source}*\n",  # æ–°å¢æ ‡é¢˜æ¨¡æ¿ â˜…
            "template": "*{subject}*\n[more]({url})",
            "preview": False,                             # ç¦æ­¢é¢„è§ˆ
            "show_count": False                       #è®¡æ•°
        }
    }
]

# ========== æ•°æ®åº“é€‚é…å±‚ ==========
USE_PG = False  # ä»…ç”¨æœ¬åœ°æ•°æ®åº“
PG_URL = None

class RSSDatabase:
    def __init__(self, loop=None):
        self.loop = loop or asyncio.get_event_loop()
        self.conn = None

    async def open(self):
        import sqlite3
        self.conn = sqlite3.connect(DATABASE_FILE, check_same_thread=False)

    async def close(self):
        if self.conn:
            self.conn.close()

    async def create_tables(self):
        def _create():
            c = self.conn.cursor()
            c.execute("""
            CREATE TABLE IF NOT EXISTS rss_status (
                feed_group TEXT,
                feed_url TEXT,
                entry_url TEXT,
                entry_content_hash TEXT,
                entry_timestamp REAL,
                PRIMARY KEY (feed_group, feed_url, entry_url)
            )""")
            c.execute("""
            CREATE UNIQUE INDEX IF NOT EXISTS idx_group_content_hash
            ON rss_status(feed_group, entry_content_hash);
            """)
            c.execute("""
            CREATE TABLE IF NOT EXISTS timestamps (
                feed_group TEXT PRIMARY KEY,
                last_run_time REAL
            )""")
            c.execute("""
            CREATE TABLE IF NOT EXISTS cleanup_timestamps (
                feed_group TEXT PRIMARY KEY,
                last_cleanup_time REAL
            )""")
            self.conn.commit()
        await self.loop.run_in_executor(None, _create)

    async def save_status(self, feed_group, feed_url, entry_url, entry_content_hash, timestamp):
        def _save():
            c = self.conn.cursor()
            c.execute(
                "INSERT OR IGNORE INTO rss_status VALUES (?, ?, ?, ?, ?)",
                (feed_group, feed_url, entry_url, entry_content_hash, timestamp)
            )
            self.conn.commit()
        await self.loop.run_in_executor(None, _save)

    async def has_content_hash(self, feed_group, content_hash):
        def _has():
            c = self.conn.cursor()
            c.execute(
                "SELECT 1 FROM rss_status WHERE feed_group=? AND entry_content_hash=? LIMIT 1",
                (feed_group, content_hash)
            )
            return c.fetchone() is not None
        return await self.loop.run_in_executor(None, _has)

    async def load_status(self):
        def _load():
            c = self.conn.cursor()
            c.execute("SELECT feed_url, entry_url FROM rss_status")
            status = {}
            for feed_url, entry_url in c.fetchall():
                status.setdefault(feed_url, set()).add(entry_url)
            return status
        return await self.loop.run_in_executor(None, _load)

    async def load_last_run_time(self, feed_group):
        def _load():
            c = self.conn.cursor()
            c.execute("SELECT last_run_time FROM timestamps WHERE feed_group = ?", (feed_group,))
            result = c.fetchone()
            return result[0] if result else 0
        return await self.loop.run_in_executor(None, _load)

    async def save_last_run_time(self, feed_group, last_run_time):
        def _save():
            c = self.conn.cursor()
            c.execute("""
                INSERT OR REPLACE INTO timestamps (feed_group, last_run_time)
                VALUES (?, ?)
            """, (feed_group, last_run_time))
            self.conn.commit()
        await self.loop.run_in_executor(None, _save)

    async def cleanup_history(self, days, feed_group):
        now = time.time()
        cutoff_ts = now - days * 86400
        def _cleanup():
            c = self.conn.cursor()
            c.execute(
                "SELECT last_cleanup_time FROM cleanup_timestamps WHERE feed_group = ?",
                (feed_group,)
            )
            result = c.fetchone()
            last_cleanup = result[0] if result else 0
            if now - last_cleanup < 86400:
                return
            c.execute(
                "DELETE FROM rss_status WHERE feed_group=? AND entry_timestamp < ?",
                (feed_group, cutoff_ts)
            )
            c.execute("""
                INSERT OR REPLACE INTO cleanup_timestamps (feed_group, last_cleanup_time)
                VALUES (?, ?)
            """, (feed_group, now))
            self.conn.commit()
        await self.loop.run_in_executor(None, _cleanup)

# ========== ä¸šåŠ¡é€»è¾‘ ==========

def remove_html_tags(text):
    text = re.sub(r'#([^#\s]+)#', r'\1', text)
    text = re.sub(r'#\w+', '', text)
    text = re.sub(r'@[^\s]+', '', text).strip()
    text = re.sub(r'ã€\s*ã€‘', '', text)
    text = re.sub(r'(?<!\S)#(?!\S)', '', text)
    text = re.sub(r'(?<!\S)ï¼š(?!\S)', '', text)
    return text

def get_entry_identifier(entry):
    if hasattr(entry, 'guid') and entry.guid:
        return hashlib.sha256(entry.guid.encode()).hexdigest()
    link = getattr(entry, 'link', '')
    if link:
        try:
            parsed = urlparse(link)
            clean_link = parsed._replace(query=None, fragment=None).geturl().lower()
            return hashlib.sha256(clean_link.encode()).hexdigest()
        except Exception as e:
            logger.warning(f"URLè§£æå¤±è´¥ {link}: {e}")
    title = getattr(entry, 'title', '')
    pub_date = get_entry_timestamp(entry).isoformat() if get_entry_timestamp(entry) else ''
    return hashlib.sha256(f"{title}|||{pub_date}".encode()).hexdigest()

def get_entry_content_hash(entry):
    title = getattr(entry, 'title', '') or ''
    summary = getattr(entry, 'summary', '') or ''
    pub_date = ''
    if hasattr(entry, 'published'):
        pub_date = entry.published
    elif hasattr(entry, 'updated'):
        pub_date = entry.updated
    raw_text = (title.strip() + summary.strip() + pub_date.strip()).encode('utf-8')
    return hashlib.sha256(raw_text).hexdigest()

def signal_handler(signum, frame):
    logger.warning(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œç¨‹åºå³å°†é€€å‡ºã€‚")
    sys.exit(0)
def get_entry_timestamp(entry):
    dt = datetime.now(pytz.UTC)
    if hasattr(entry, 'published_parsed') and entry.published_parsed:
        dt = datetime(*entry.published_parsed[:6], tzinfo=pytz.utc)
    elif hasattr(entry, 'pubDate_parsed') and entry.pubDate_parsed:
        dt = datetime(*entry.pubDate_parsed[:6], tzinfo=pytz.utc)
    elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
        dt = datetime(*entry.updated_parsed[:6], tzinfo=pytz.utc)
    return dt

@retry(
    stop=stop_after_attempt(1),
    wait=wait_exponential(multiplier=1, min=5, max=30),
    retry=retry_if_exception_type((aiohttp.ClientError, asyncio.TimeoutError)),
)
async def send_single_message(bot, chat_id, text, disable_web_page_preview=False):
    try:
        MAX_MESSAGE_LENGTH = 4096
        text_chunks = []
        current_chunk = []
        current_length = 0
        paragraphs = text.split('\n\n')
        for para in paragraphs:
            para_length = len(para.encode('utf-8'))
            if current_length + para_length + 2 > MAX_MESSAGE_LENGTH:
                text_chunks.append('\n\n'.join(current_chunk))
                current_chunk = []
                current_length = 0
            current_chunk.append(para)
            current_length += para_length + 2
        if current_chunk:
            text_chunks.append('\n\n'.join(current_chunk))
        for chunk in text_chunks:
            await bot.send_message(
                chat_id=chat_id,
                text=chunk,
                parse_mode='MarkdownV2',
                disable_web_page_preview=disable_web_page_preview,
                read_timeout=10,
                write_timeout=10
            )
    except BadRequest as e:
        logging.error(f"æ¶ˆæ¯å‘é€å¤±è´¥(Markdowné”™è¯¯): {e} - æ–‡æœ¬ç‰‡æ®µ: {chunk[:200]}...")
    except Exception as e:
        raise

@retry(
    stop=stop_after_attempt(1),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_exception_type((aiohttp.ClientError, asyncio.TimeoutError)),
)
async def fetch_feed(session, feed_url):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'}
    parsed = urlparse(feed_url)
    is_rsshub = parsed.netloc == "rsshub.app"
    if is_rsshub:
        try_domains = BACKUP_DOMAINS + ["rsshub.app"]
        canonical_url = feed_url.replace(parsed.netloc, "rsshub.app")
    else:
        try_domains = [parsed.netloc]
        canonical_url = feed_url
    for domain in try_domains:
        modified_url = feed_url.replace(parsed.netloc, domain)
        try:
            async with semaphore:
                async with session.get(modified_url, headers=headers, timeout=30) as response:
                    if response.status in (503, 403, 404, 429):
                        continue
                    response.raise_for_status()
                    return parse(await response.read()), canonical_url
        except aiohttp.ClientResponseError as e:
            if e.status in (503, 403, 404, 429):
                continue
        except Exception as e:
            logger.error(f"è¯·æ±‚å¤±è´¥: {modified_url}, é”™è¯¯: {e}")
            continue
    logger.error(f"æ‰€æœ‰åŸŸåå°è¯•å¤±è´¥: {feed_url}")
    return None, canonical_url

async def translate_with_credentials(secret_id, secret_key, text):
    loop = asyncio.get_running_loop()
    text_bytes = text.encode('utf-8')
    if len(text_bytes) > 2000:
        safe_bytes = text_bytes[:2000]
        while safe_bytes[-1] & 0xC0 == 0x80:
            safe_bytes = safe_bytes[:-1]
        text = safe_bytes.decode('utf-8', errors='ignore')
        logger.warning(f"æ–‡æœ¬æˆªæ–­è‡³ {len(text)} å­—ç¬¦ ({len(safe_bytes)} å­—èŠ‚)")
    try:
        return await loop.run_in_executor(
            None, 
            lambda: _sync_translate(secret_id, secret_key, text)
        )
    except Exception as e:
        logger.error(f"ç¿»è¯‘æ‰§è¡Œå¤±è´¥: {type(e).__name__} - {str(e)}")
        raise

def _sync_translate(secret_id, secret_key, text):
    try:
        cred = credential.Credential(secret_id, secret_key)
        clientProfile = ClientProfile(httpProfile=HttpProfile(endpoint="tmt.tencentcloudapi.com"))
        client = tmt_client.TmtClient(cred, TENCENT_REGION, clientProfile)
        req = models.TextTranslateRequest()
        req.SourceText = remove_html_tags(text)
        req.Source = "auto"
        req.Target = "zh"
        req.ProjectId = 0
        return client.TextTranslate(req).TargetText
    except TencentCloudSDKException as e:
        error_details = {
            "code": e.code,
            "message": e.message,
            "request_id": e.request_id,
            "region": TENCENT_REGION
        }
        logger.error(f"è…¾è®¯äº‘APIé”™è¯¯è¯¦æƒ…: {error_details}")
        raise
    except Exception as e:
        logger.error(f"ç¿»è¯‘è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
        raise

@retry(
    stop=stop_after_attempt(2),
    wait=wait_exponential(multiplier=1, min=2, max=10),
)
async def auto_translate_text(text):
    try:
        try:
            return await translate_with_credentials(
                TENCENTCLOUD_SECRET_ID, 
                TENCENTCLOUD_SECRET_KEY,
                text
            )
        except TencentCloudSDKException as e:
            logger.error(f"ä¸»å¯†é’¥ç¿»è¯‘å¤±è´¥: [Code: {e.code}] {e.message}")
            raise
        except Exception as e:
            logger.error(f"ä¸»å¯†é’¥ç¿»è¯‘æœªçŸ¥é”™è¯¯: {type(e).__name__} - {str(e)}")
            raise
    except Exception as first_error:
        if TENCENT_SECRET_ID and TENCENT_SECRET_KEY:
            logger.warning("ä¸»ç¿»è¯‘å¯†é’¥å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨å¯†é’¥...")
            try:
                return await translate_with_credentials(
                    TENCENT_SECRET_ID,
                    TENCENT_SECRET_KEY,
                    text
                )
            except TencentCloudSDKException as e:
                logger.error(f"å¤‡ç”¨å¯†é’¥ç¿»è¯‘å¤±è´¥: [Code: {e.code}] {e.message}")
                raise
            except Exception as e:
                logger.error(f"å¤‡ç”¨å¯†é’¥ç¿»è¯‘æœªçŸ¥é”™è¯¯: {type(e).__name__} - {str(e)}")
                raise
        else:
            logger.error("ä¸»ç¿»è¯‘å¯†é’¥å¤±è´¥ï¼Œä¸”æœªé…ç½®å¤‡ç”¨å¯†é’¥")
            raise first_error
    except Exception as final_error:
        logger.error(f"æ‰€æœ‰ç¿»è¯‘å°è¯•å‡å¤±è´¥: {type(final_error).__name__}")
        cleaned = remove_html_tags(text)
        return escape(cleaned)

async def generate_group_message(feed_data, entries, processor):
    try:
        source_name = feed_data.feed.get('title', "æœªçŸ¥æ¥æº")
        safe_source = escape(source_name)
        header = ""
        if "header_template" in processor:
            header = processor["header_template"].format(source=safe_source) + "\n"
        messages = []
        for entry in entries:
            raw_subject = remove_html_tags(entry.title or "æ— æ ‡é¢˜")
            if processor["translate"]:
                translated_subject = await auto_translate_text(raw_subject)
            else:
                translated_subject = raw_subject
            safe_subject = escape(translated_subject)
            raw_url = entry.link
            safe_url = escape(raw_url)
            message = processor["template"].format(
                subject=safe_subject,
                source=safe_source,
                url=safe_url
            )
            messages.append(message)
        full_message = header + "\n\n".join(messages)
        if processor.get("show_count", True):
            full_message += f"\n\nâœ… æ–°å¢ {len(messages)} æ¡å†…å®¹"
        return full_message
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ¶ˆæ¯å¤±è´¥: {str(e)}")
        return ""

async def process_group(session, group_config, global_status, db: RSSDatabase):
    group_name = group_config["name"]
    group_key = group_config["group_key"]
    processor = group_config["processor"]
    bot_token = group_config["bot_token"]
    try:
        last_run = await db.load_last_run_time(group_key)
        now = datetime.now(pytz.utc).timestamp()
        if (now - last_run) < group_config["interval"]:
            return
        bot = Bot(token=bot_token)
        for index, feed_url in enumerate(group_config["urls"]):
            try:
                if index > 0:
                    await asyncio.sleep(1)
                feed_data, canonical_url = await fetch_feed(session, feed_url)
                if not feed_data or not feed_data.entries:
                    continue
                processed_ids = global_status.get(canonical_url, set())
                new_entries = []
                seen_in_batch = set()
                for entry in feed_data.entries:
                    entry_id = get_entry_identifier(entry)
                    content_hash = get_entry_content_hash(entry)
                    # å¦‚æœå†…å®¹hashå·²å­˜åœ¨åˆ™è·³è¿‡ï¼ˆå³ä½¿entry_idä¸åŒï¼‰
                    if await db.has_content_hash(group_key, content_hash):
                        continue
                    if entry_id in processed_ids or entry_id in seen_in_batch:
                        continue
                    seen_in_batch.add(entry_id)
                    filter_config = processor.get("filter", {})
                    if filter_config.get("enable", False):
                        raw_title = remove_html_tags(entry.title or "")
                        keywords = filter_config.get("keywords", [])
                        match = any(kw.lower() in raw_title.lower() for kw in keywords)
                        if filter_config.get("mode", "allow") == "allow":
                            if not match:
                                continue
                        else:
                            if match:
                                continue
                    # ä¿å­˜entryã€hashã€id
                    new_entries.append((entry, content_hash, entry_id))
                if new_entries:
                    feed_message = await generate_group_message(feed_data, [e for e,_,_ in new_entries], processor)
                    if feed_message:
                        try:
                            await send_single_message(
                                bot,
                                TELEGRAM_CHAT_ID[0],
                                feed_message,
                                disable_web_page_preview=not processor.get("preview", True)
                            )
                            for entry, content_hash, entry_id in new_entries:
                                await db.save_status(group_key, canonical_url, entry_id, content_hash, time.time())
                                processed_ids.add(entry_id)
                            global_status[canonical_url] = processed_ids
                        except Exception as send_error:
                            logger.error(f"âŒ å‘é€æ¶ˆæ¯å¤±è´¥ [{feed_url}]")
                            raise
            except Exception as e:
                logger.error(f"âŒ å¤„ç†å¤±è´¥ [{feed_url}]")
        await db.save_last_run_time(group_key, now)
    except Exception as e:
        logger.critical(f"â€¼ï¸ å¤„ç†ç»„å¤±è´¥ [{group_key}]")

async def main():
    lock_file = None
    db = RSSDatabase()
    try:
        lock_file = open(LOCK_FILE, "w")
        fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
    except OSError:
        logger.warning("â›” æ— æ³•è·å–æ–‡ä»¶é”ï¼Œå·²æœ‰å®ä¾‹åœ¨è¿è¡Œï¼Œç¨‹åºé€€å‡º")
        return
    except Exception as e:
        logger.critical(f"â€¼ï¸ æ–‡ä»¶é”å¼‚å¸¸: {str(e)}")
        return
    try:
        await db.open()
        await db.create_tables()
    except Exception as e:
        logger.critical(f"â€¼ï¸ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return
    for group in RSS_GROUPS:
        days = group.get("history_days", 30)
        try:
            await db.cleanup_history(days, group["group_key"])
        except Exception as e:
            logger.error(f"æ¸…ç†å†å²è®°å½•å¼‚å¸¸: ç»„={group['group_key']}, é”™è¯¯={e}")
    async with aiohttp.ClientSession() as session:
        try:
            status = await db.load_status()
            tasks = []
            for group in RSS_GROUPS:
                try:
                    tasks.append(process_group(session, group, status, db))
                except Exception as e:
                    logger.error(f"âš ï¸ åˆ›å»ºä»»åŠ¡å¤±è´¥ [{group['name']}]: {str(e)}")
            if tasks:
                results = await asyncio.gather(*tasks, return_exceptions=True)
                for res in results:
                    if isinstance(res, Exception):
                        logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {res}")
            else:
                logger.warning("â›” æœªåˆ›å»ºä»»ä½•å¤„ç†ä»»åŠ¡")
        except asyncio.CancelledError:
            logger.warning("â¹ï¸ ä»»åŠ¡è¢«å–æ¶ˆ")
        except Exception as e:
            logger.critical(f"â€¼ï¸ ä¸»å¾ªç¯å¼‚å¸¸: {str(e)}", exc_info=True)
        finally:
            try:
                await session.close()
            except Exception as e:
                logger.error(f"âš ï¸ å…³é—­ä¼šè¯å¤±è´¥: {str(e)}")
    try:
        if lock_file:
            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
            lock_file.close()
    except Exception as e:
        logger.error(f"âš ï¸ é‡Šæ”¾æ–‡ä»¶é”å¤±è´¥: {str(e)}")
    await db.close()

if __name__ == "__main__":
    for s in (signal.SIGINT, signal.SIGTERM):
        signal.signal(s, signal_handler)
    try:
        asyncio.run(main())
    except Exception as e:
        logger.critical(f"â€¼ï¸ ä¸»è¿›ç¨‹æœªæ•è·å¼‚å¸¸: {str(e)}", exc_info=True)
        sys.exit(1)