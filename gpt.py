#source rss_venv/bin/activate
#pip install python-dotenv python-telegram-bot Pillow google-generativeai md2tgmd aiohttp
# sudo systemctl restart gpt.service
import asyncio
import os
import time
import traceback
import io
import re
import json
from typing import Dict, List, Optional
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from telegram.constants import ParseMode
from PIL import Image
import google.generativeai as genai
from md2tgmd import escape
import aiohttp
from aiohttp import ClientTimeout

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®ä¿¡æ¯
TG_TOKEN = os.getenv("TELEGRAM_GEMINI_KEY")
GOOGLE_GEMINI_KEY = os.getenv("GEMINI_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
ALLOWED_USER_IDS_STR = os.getenv("TELEGRAM_CHAT_ID")
DEFAULT_MODEL = os.getenv("GPT_ENGINE", "gemini-2.5-flash")

# è¶…æ—¶é…ç½®
POLLING_TIMEOUT = int(os.getenv("POLLING_TIMEOUT", "45"))

# å¯ç”¨æ¨¡å‹åˆ—è¡¨
AVAILABLE_MODELS = {
    "gemini-2.5-flash": "(å¹³è¡¡æ€§èƒ½)",
    "deepseek-chat":    "(é€šç”¨å¯¹è¯)",
    "deepseek-reasoner":"(æ¨ç†ä¸“ç”¨)",
    "deepseek-coder":   "(ç¼–ç¨‹ä¸“ç”¨)"
}

# é”™è¯¯ä¿¡æ¯é…ç½®
ERROR_INFO = "âš ï¸âš ï¸âš ï¸\nå‡ºäº†é—®é¢˜ !\nè¯·å°è¯•æ›´æ”¹æ‚¨çš„æç¤ºæˆ–è”ç³»ç®¡ç†å‘˜ !"
BEFORE_GENERATE_INFO = "ğŸ¤–GeneratingğŸ¤–"
DOWNLOAD_PIC_NOTIFY = "ğŸ¤–Loading pictureğŸ¤–"

# åˆå§‹åŒ–é…ç½®
try:
    ALLOWED_USER_IDS = [int(user_id.strip()) for user_id in ALLOWED_USER_IDS_STR.split(",")] if ALLOWED_USER_IDS_STR else []
except ValueError:
    exit(1)

# åˆå§‹åŒ–Gemini
try:
    genai.configure(api_key=GOOGLE_GEMINI_KEY)
except Exception as e:
    exit(1)

# ä¼šè¯ç®¡ç†
class UserSession:
    def __init__(self, chat_session: genai.ChatSession = None, model_name: str = DEFAULT_MODEL, deepseek_history: List = None):
        self.chat_session = chat_session
        self.last_activity = time.time()
        self.model_name = model_name
        self.message_count = 0
        self.total_tokens = 0
        self.deepseek_history = deepseek_history or []

# ä¼šè¯å­—å…¸
user_sessions: Dict[int, UserSession] = {}

# é…ç½®éªŒè¯
def validate_config():
    """éªŒè¯é…ç½®"""
    errors = []
    
    if not TG_TOKEN:
        errors.append("TELEGRAM_GEMINI_KEY æœªè®¾ç½®")
    if not GOOGLE_GEMINI_KEY:
        errors.append("GEMINI_API_KEY æœªè®¾ç½®")
    if not ALLOWED_USER_IDS:
        errors.append("TELEGRAM_CHAT_ID æœªè®¾ç½®")
    
    if errors:
        return False
    
    return True

# è¾…åŠ©å‡½æ•°
def get_current_model_info(user_id: int) -> str:
    """è·å–å½“å‰æ¨¡å‹ä¿¡æ¯"""
    if user_id in user_sessions:
        model_name = user_sessions[user_id].model_name
        return f"`{model_name}` - {AVAILABLE_MODELS.get(model_name, 'æœªçŸ¥æ¨¡å‹')}"
    return f"`{DEFAULT_MODEL}` - {AVAILABLE_MODELS.get(DEFAULT_MODEL, 'é»˜è®¤æ¨¡å‹')}"

def get_user_session(user_id: int, model_name: str = None) -> UserSession:
    """æ™ºèƒ½ä¼šè¯ç®¡ç† - è‡ªåŠ¨æ¸…ç†è¿‡é•¿ä¸Šä¸‹æ–‡"""
    now = time.time()
    
    # æ¸…ç†è¿‡æœŸä¼šè¯ï¼ˆ1å°æ—¶ï¼‰
    expired_users = [uid for uid, session in user_sessions.items() if now - session.last_activity > 3600]
    for uid in expired_users:
        del user_sessions[uid]

    if user_id not in user_sessions:
        if not model_name:
            model_name = DEFAULT_MODEL
        
        if model_name.startswith("gemini"):
            model = genai.GenerativeModel(model_name)
            chat = model.start_chat(history=[])
            user_sessions[user_id] = UserSession(chat, model_name)
        else:
            # DeepSeekæ¨¡å‹
            user_sessions[user_id] = UserSession(model_name=model_name, deepseek_history=[])
    else:
        # å¦‚æœåˆ‡æ¢äº†æ¨¡å‹ï¼Œåº”è¯¥åˆ›å»ºæ–°çš„ä¼šè¯
        current_session = user_sessions[user_id]
        if model_name and model_name != current_session.model_name:
            if model_name.startswith("gemini"):
                model = genai.GenerativeModel(model_name)
                chat = model.start_chat(history=[])
                user_sessions[user_id] = UserSession(chat, model_name)
            else:
                # DeepSeekæ¨¡å‹
                user_sessions[user_id] = UserSession(model_name=model_name, deepseek_history=[])
        else:
            user_sessions[user_id].last_activity = now
        
        # æ™ºèƒ½ä¸Šä¸‹æ–‡æ¸…ç†ç­–ç•¥ï¼ˆä»…å¯¹Geminiæ¨¡å‹ï¼‰
        session = user_sessions[user_id]
        if session.chat_session and hasattr(session.chat_session, 'history'):
            history_length = len(session.chat_session.history)
            if history_length > 20:
                keep_count = min(16, history_length)
                session.chat_session.history = session.chat_session.history[-keep_count:]
            elif history_length > 15:
                keep_count = min(12, history_length)
                session.chat_session.history = session.chat_session.history[-keep_count:]
        
    return user_sessions[user_id]

def clear_user_context(user_id: int):
    """æ¸…ç©ºç”¨æˆ·å¯¹è¯ä¸Šä¸‹æ–‡"""
    if user_id in user_sessions:
        del user_sessions[user_id]

def is_user_allowed(update: Update):
    """æ£€æŸ¥ç”¨æˆ·æƒé™"""
    return update.effective_user.id in ALLOWED_USER_IDS

def prepare_markdown_segment(text: str) -> str:
    """ä½¿ç”¨md2tgmd.escapeç»Ÿä¸€è½¬ä¹‰æ–‡æœ¬æ®µ"""
    return escape(text)

# ==================== DeepSeek API è°ƒç”¨ ====================
async def call_deepseek_api(user_message: str, user_session: UserSession) -> str:
    """è°ƒç”¨DeepSeek API"""
    if not DEEPSEEK_API_KEY:
        raise Exception("DeepSeek API Key æœªé…ç½®")
    
    # æ„å»ºæ¶ˆæ¯å†å²
    messages = []
    
    # æ·»åŠ ä¸Šä¸‹æ–‡å†å²ï¼ˆæœ€å¤šä¿ç•™6è½®å¯¹è¯ï¼‰
    history = user_session.deepseek_history[-12:]  # ä¿ç•™æœ€è¿‘6è½®
    messages.extend(history)
    
    # æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼Œä¼˜åŒ– Telegram Markdown V2 æ ¼å¼è¾“å‡º
    system_prompt = """standard Markdown format"""
    
    # å¦‚æœæ˜¯æ–°å¯¹è¯ï¼Œæ·»åŠ ç³»ç»Ÿæç¤º
    if not history:
        messages.insert(0, {"role": "system", "content": system_prompt})
    
    # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    messages.append({"role": "user", "content": user_message})
    
    # APIè¯·æ±‚æ•°æ®
    data = {
        "model": user_session.model_name,
        "messages": messages,
        "stream": False,
        "max_tokens": 4000
    }
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
    }
    
    timeout = ClientTimeout(total=60)
    async with aiohttp.ClientSession(timeout=timeout) as session:
        async with session.post(
            "https://api.deepseek.com/chat/completions",
            json=data,
            headers=headers
        ) as response:
            if response.status != 200:
                error_text = await response.text()
                raise Exception(f"DeepSeek API é”™è¯¯: {response.status} - {error_text}")
            
            result = await response.json()
            full_response = result['choices'][0]['message']['content']
            
            # æ›´æ–°å¯¹è¯å†å²
            user_session.deepseek_history.append({"role": "user", "content": user_message})
            user_session.deepseek_history.append({"role": "assistant", "content": full_response})
            
            # é™åˆ¶å†å²é•¿åº¦
            if len(user_session.deepseek_history) > 20:
                user_session.deepseek_history = user_session.deepseek_history[-20:]
            
            return full_response

# ==================== æ¶ˆæ¯åˆ†å‰²åŠŸèƒ½ ====================
def split_messages(text: str) -> List[str]:
    """
    æ™ºèƒ½åˆ†å‰²æ¶ˆæ¯ï¼Œç¡®ä¿ï¼š
    1. ä¼˜å…ˆåœ¨æ®µè½è¾¹ç•Œåˆ†å‰²
    2. ä¸ç ´åä»£ç å—ç»“æ„
    3. æ¯æ®µä¸è¶…è¿‡3900å­—èŠ‚
    """
    MAX_BYTES = 3900
    chunks = []
    current_chunk = ""

    # æŒ‰æ®µè½åˆ†å‰²
    paragraphs = text.split('\n\n')
    for para in paragraphs:
        para_bytes_len = len(para.encode('utf-8'))
        current_chunk_bytes_len = len(current_chunk.encode('utf-8'))

        if current_chunk_bytes_len + 4 + para_bytes_len > MAX_BYTES:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = para
        else:
            current_chunk += '\n\n' + para if current_chunk else para

    if current_chunk:
        chunks.append(current_chunk)

    # äºŒæ¬¡åˆ†å‰²è¶…é•¿æ®µè½
    final_chunks = []
    for chunk in chunks:
        chunk_bytes_len = len(chunk.encode('utf-8'))
        if chunk_bytes_len <= MAX_BYTES:
            final_chunks.append(chunk)
        else:
            sentences = re.split(r'(?<=[.!?])\s+', chunk)
            current = ""
            current_bytes_len = 0
            for sent in sentences:
                sent_bytes_len = len(sent.encode('utf-8'))
                if current_bytes_len + 1 + sent_bytes_len > MAX_BYTES:
                    if current:
                        final_chunks.append(current)
                    current = sent
                    current_bytes_len = sent_bytes_len
                else:
                    current += ' ' + sent if current else sent
                    current_bytes_len += (1 + sent_bytes_len) if current else sent_bytes_len
            if current:
                final_chunks.append(current)

    return final_chunks

async def send_segmented_message(bot, chat_id: int, message_id: int, text: str):
    """åˆ†æ®µå‘é€æ¶ˆæ¯ - ä¿®å¤ç‰ˆæœ¬"""
    chunks = split_messages(text)
    
    if not chunks:
        return
    
    sent_messages = []
    
    # å‘é€æ‰€æœ‰æ®µè½
    for i, chunk in enumerate(chunks):
        try:
            if i == 0:  # ç¬¬ä¸€æ®µä½œä¸ºå›å¤
                sent_msg = await bot.send_message(
                    chat_id,
                    escape(chunk),
                    reply_to_message_id=message_id,
                    parse_mode=ParseMode.MARKDOWN_V2
                )
            else:  # åç»­æ®µè½ä½œä¸ºæ–°æ¶ˆæ¯
                sent_msg = await bot.send_message(
                    chat_id,
                    escape(chunk),
                    parse_mode=ParseMode.MARKDOWN_V2
                )
            sent_messages.append(sent_msg)
        except Exception as e:
            # å¦‚æœMarkdownå‘é€å¤±è´¥ï¼Œå°è¯•æ™®é€šæ–‡æœ¬
            if i == 0:
                sent_msg = await bot.send_message(
                    chat_id,
                    chunk,
                    reply_to_message_id=message_id
                )
            else:
                sent_msg = await bot.send_message(chat_id, chunk)
            sent_messages.append(sent_msg)
        
        await asyncio.sleep(0.3)  # é¿å…å‘é€è¿‡å¿«
    
    return sent_messages

# ==================== AI å¤„ç†å‡½æ•° ====================
async def ai_handler(bot, chat_id: int, message_id: int, user_message: str, model_type: str, user_id: int):
    """ç»Ÿä¸€çš„AIå¤„ç†å‡½æ•° - ä¼˜åŒ–ç‰ˆæœ¬"""
    sent_message = None
    try:
        # å‘é€ç”Ÿæˆä¸­æç¤º
        sent_message = await bot.send_message(
            chat_id, 
            BEFORE_GENERATE_INFO,
            reply_to_message_id=message_id
        )

        # è·å–æˆ–åˆ›å»ºç”¨æˆ·ä¼šè¯
        try:
            user_session = get_user_session(user_id, model_type)
        except Exception as e:
            clear_user_context(user_id)
            user_session = get_user_session(user_id, model_type)
        
        full_response = ""

        # æ ¹æ®æ¨¡å‹ç±»å‹è°ƒç”¨ä¸åŒçš„API
        if model_type.startswith("gemini"):
            enhanced_message = f"ç”¨ä¸­æ–‡å›å¤ï¼š{user_message}"
            
            try:
                response = user_session.chat_session.send_message(enhanced_message)
                full_response = response.text
            except Exception as e:
                await bot.edit_message_text(
                    f"{ERROR_INFO}\né”™è¯¯è¯¦æƒ…: {str(e)}",
                    chat_id=chat_id,
                    message_id=sent_message.message_id
                )
                return
                
        else:
            enhanced_message = f"ç”¨ä¸­æ–‡å›å¤ï¼š{user_message}"
            full_response = await call_deepseek_api(enhanced_message, user_session)
        
        # å¤„ç†å®Œæ•´å“åº”
        if full_response:
            response_bytes = len(full_response.encode('utf-8'))
            
            if response_bytes > 3900:
                # é•¿æ¶ˆæ¯ï¼šä¿ç•™Generatingæç¤ºï¼Œç›´æ¥åˆ†æ®µå‘é€å›å¤
                await send_segmented_message(bot, chat_id, message_id, full_response)
                # Generatingæç¤ºä¿æŒæ˜¾ç¤ºï¼Œè®©ç”¨æˆ·çŸ¥é“ç”Ÿæˆå·²å®Œæˆ
                    
            else:
                # çŸ­æ¶ˆæ¯ï¼šç›´æ¥ç¼–è¾‘Generatingæç¤ºä¸ºæœ€ç»ˆå›å¤
                try:
                    await bot.edit_message_text(
                        escape(full_response),
                        chat_id=chat_id,
                        message_id=sent_message.message_id,
                        parse_mode=ParseMode.MARKDOWN_V2
                    )
                except Exception as e:
                    await bot.edit_message_text(
                        full_response,
                        chat_id=chat_id,
                        message_id=sent_message.message_id
                    )

    except asyncio.TimeoutError:
        if sent_message:
            await bot.edit_message_text(
                "â° è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•",
                chat_id=chat_id,
                message_id=sent_message.message_id
            )
    except Exception as e:
        if sent_message:
            try:
                await bot.edit_message_text(
                    f"{ERROR_INFO}\né”™è¯¯è¯¦æƒ…: {str(e)}",
                    chat_id=chat_id,
                    message_id=sent_message.message_id
                )
            except Exception:
                await bot.send_message(
                    chat_id,
                    f"{ERROR_INFO}\né”™è¯¯è¯¦æƒ…: {str(e)}",
                    reply_to_message_id=message_id
                )

# ==================== å›¾ç‰‡å¤„ç†åŠŸèƒ½ ====================
async def download_image_with_retry(file_id: str, application: Application) -> Optional[bytes]:
    """å¸¦é‡è¯•æœºåˆ¶çš„å›¾ç‰‡ä¸‹è½½"""
    try:
        file = await application.bot.get_file(file_id)
        file_url = file.file_path
        
        timeout = ClientTimeout(total=30)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(file_url) as response:
                response.raise_for_status()
                return await response.read()
    except Exception as e:
        return None

async def gemini_edit_handler(bot, chat_id: int, message_id: int, user_message: str, photo_file: bytes, user_id: int):
    """å›¾ç‰‡ç¼–è¾‘å¤„ç†å‡½æ•°"""
    try:
        processing_msg = await bot.send_message(chat_id, DOWNLOAD_PIC_NOTIFY, reply_to_message_id=message_id)
        
        image = Image.open(io.BytesIO(photo_file))
        user_session = get_user_session(user_id, "gemini-2.5-flash")
        
        enhanced_message = f"ç”¨ä¸­æ–‡å›å¤ï¼š{user_message}" if user_message else "ç”¨ä¸­æ–‡æè¿°è¿™å¼ å›¾ç‰‡"
        contents = [enhanced_message, image]
        
        response = user_session.chat_session.send_message(contents)
        
        response_text = ""
        for part in response.parts:
            if hasattr(part, 'text') and part.text:
                response_text += part.text
        
        await bot.delete_message(chat_id, processing_msg.message_id)
        
        if response_text:
            await send_segmented_message(bot, chat_id, message_id, response_text)
        
    except Exception as e:
        await bot.send_message(chat_id, f"{ERROR_INFO}\nError: {str(e)}", reply_to_message_id=message_id)

# ==================== å‘½ä»¤å¤„ç†å‡½æ•° ====================
async def handle_start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†/startå‘½ä»¤"""
    if not is_user_allowed(update):
        return
    
    help_text = """
ğŸ¤– **AI åŠ©æ‰‹æœºå™¨äºº**

# ç®€åŒ–å‘½ä»¤ï¼š
`/new`   - å¼€å§‹æ–°å¯¹è¯ï¼ˆæ¸…ç©ºä¸Šä¸‹æ–‡ï¼‰
`/model` - åˆ‡æ¢AIæ¨¡å‹
`/setup` - è®¾ç½®é€‰é¡¹

# å½“å‰é»˜è®¤æ¨¡å‹ï¼š
{model_info}

ç›´æ¥å‘é€æ¶ˆæ¯å¼€å§‹å¯¹è¯ï¼
    """.format(model_info=get_current_model_info(update.effective_user.id))
    
    await update.message.reply_text(prepare_markdown_segment(help_text), 
                                  parse_mode=ParseMode.MARKDOWN_V2)

async def handle_new_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†/newå‘½ä»¤ - å¼€å§‹æ–°å¯¹è¯ï¼ˆæ¸…ç©ºä¸Šä¸‹æ–‡ï¼‰"""
    if not is_user_allowed(update):
        return
    
    clear_user_context(update.effective_user.id)
    await update.message.reply_text("ğŸ†• å·²å¼€å§‹æ–°å¯¹è¯ï¼Œä¸Šä¸‹æ–‡å†å²å·²æ¸…ç©º")

async def handle_model_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†/modelå‘½ä»¤ - åˆ‡æ¢AIæ¨¡å‹"""
    if not is_user_allowed(update):
        return
    
    user_id = update.effective_user.id
    
    if not context.args:
        current_model = get_current_model_info(user_id)
        
        model_text = f"""
ğŸ”„ **æ¨¡å‹åˆ‡æ¢**

**å½“å‰æ¨¡å‹ï¼š**
{current_model}

**gemini:**
`/model gemini-2.5-flash`  (å¹³è¡¡æ€§èƒ½)

**deekseek:**
`/model deepseek-chat`          (é€šç”¨å¯¹è¯)
`/model deepseek-coder`        (ç¼–ç¨‹ä¸“ç”¨)
`/model deepseek-reasoner`  (æ¨ç†ä¸“ç”¨)

**ç›´æ¥ç‚¹å‡»ä¸Šé¢çš„å‘½ä»¤å³å¯åˆ‡æ¢**
        """
        await update.message.reply_text(prepare_markdown_segment(model_text), 
                                      parse_mode=ParseMode.MARKDOWN_V2)
        return
    
    model_name = context.args[0].strip()
    if model_name not in AVAILABLE_MODELS:
        available_models = "\n".join([f"â€¢ `{model}` - {desc}" for model, desc in AVAILABLE_MODELS.items()])
        await update.message.reply_text(
            prepare_markdown_segment(f"âŒ æ— æ•ˆçš„æ¨¡å‹åç§°ã€‚\n\nå¯ç”¨æ¨¡å‹ï¼š\n{available_models}"),
            parse_mode=ParseMode.MARKDOWN_V2
        )
        return
    
    if user_id in user_sessions:
        if user_sessions[user_id].model_name == model_name:
            await update.message.reply_text(
                prepare_markdown_segment(f"â„¹ï¸ å·²ç»æ˜¯ `{model_name}` æ¨¡å‹"),
                parse_mode=ParseMode.MARKDOWN_V2
            )
            return
        else:
            del user_sessions[user_id]
    
    try:
        get_user_session(user_id, model_name)
        await update.message.reply_text(
            prepare_markdown_segment(f"âœ… å·²åˆ‡æ¢åˆ°æ¨¡å‹ï¼š`{model_name}`\n{AVAILABLE_MODELS[model_name]}"),
            parse_mode=ParseMode.MARKDOWN_V2
        )
    except Exception as e:
        await update.message.reply_text(
            prepare_markdown_segment(f"âŒ åˆ‡æ¢æ¨¡å‹å¤±è´¥ï¼š{str(e)}"),
            parse_mode=ParseMode.MARKDOWN_V2
        )

async def handle_setup_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†/setupå‘½ä»¤ - è®¾ç½®é€‰é¡¹"""
    if not is_user_allowed(update):
        return
    
    setup_text = """
âš™ï¸ **è®¾ç½®é€‰é¡¹**

# å¿«æ·æ“ä½œï¼š
`/new`        - ğŸ†• æ¸…ç©ºå¯¹è¯å†å²
`/model` - ğŸ”„ åˆ‡æ¢AIæ¨¡å‹
`/clear` - ğŸ”„ æ¸…ç©ºå¯¹è¯ä¸Šä¸‹æ–‡
`/start` - ğŸ¤– æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

** ç³»ç»ŸçŠ¶æ€ï¼š**
â€¢ é»˜è®¤æ¨¡å‹ï¼š{model_info}
â€¢ ä¸Šä¸‹æ–‡ç®¡ç†ï¼šâœ… æ™ºèƒ½æ¸…ç†

**ä½¿ç”¨æç¤ºï¼š**
ç›´æ¥å‘é€æ¶ˆæ¯å³å¯å¼€å§‹å¯¹è¯ï¼
å‘é€å›¾ç‰‡å¯è¿›è¡Œå›¾åƒåˆ†æ
    """.format(model_info=get_current_model_info(update.effective_user.id))
    
    await update.message.reply_text(prepare_markdown_segment(setup_text), 
                                  parse_mode=ParseMode.MARKDOWN_V2)

async def handle_clear_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """æ¸…ç©ºå¯¹è¯ä¸Šä¸‹æ–‡"""
    if not is_user_allowed(update):
        return
    
    clear_user_context(update.effective_user.id)
    await update.message.reply_text("âœ… å¯¹è¯å†å²å·²æ¸…ç©º")

async def handle_photo_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†å›¾ç‰‡æ¶ˆæ¯"""
    if not is_user_allowed(update):
        return
    
    file_id = update.message.photo[-1].file_id
    photo_data = await download_image_with_retry(file_id, context.application)
    
    if not photo_data:
        await update.message.reply_text("Failed to download image")
        return
    
    user_message = update.message.caption or ""
    
    await gemini_edit_handler(
        context.bot,
        update.effective_chat.id,
        update.message.message_id,
        user_message,
        photo_data,
        update.effective_user.id
    )

async def handle_private_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†ç§èŠæ¶ˆæ¯"""
    if not is_user_allowed(update) or update.effective_chat.type != "private":
        return
    
    user_message = update.message.text.strip()
    user_id = update.effective_user.id
    
    if user_id in user_sessions:
        model_type = user_sessions[user_id].model_name
    else:
        model_type = DEFAULT_MODEL
    
    await ai_handler(
        context.bot,
        update.effective_chat.id,
        update.message.message_id,
        user_message,
        model_type,
        user_id
    )

# ==================== æ¸…ç†ä»»åŠ¡ ====================
async def cleanup_task(context: ContextTypes.DEFAULT_TYPE):
    """æ¸…ç†è¿‡æœŸä¼šè¯"""
    now = time.time()
    expired = [uid for uid, session in user_sessions.items() if now - session.last_activity > 3600]
    for uid in expired:
        del user_sessions[uid]

def main():
    """ä¸»å‡½æ•°"""
    if not validate_config():
        return
    
    application = Application.builder().token(TG_TOKEN).build()
    
    application.add_handler(CommandHandler("start", handle_start_command))
    application.add_handler(CommandHandler("new", handle_new_command))
    application.add_handler(CommandHandler("model", handle_model_command))
    application.add_handler(CommandHandler("setup", handle_setup_command))
    application.add_handler(CommandHandler("clear", handle_clear_command))
    
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo_message))
    application.add_handler(MessageHandler(
        filters.TEXT & ~filters.COMMAND & filters.ChatType.PRIVATE, 
        handle_private_message
    ))
    
    job_queue = application.job_queue
    job_queue.run_repeating(cleanup_task, interval=3600, first=10)
    
    application.run_polling(
        allowed_updates=["message", "callback_query"],
        timeout=POLLING_TIMEOUT
    )

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        pass
    except Exception as e:
        traceback.print_exc()