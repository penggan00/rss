#source rss_venv/bin/activate
#pip install html2text requests pdfplumber beautifulsoup4 md2tgmd python-dotenv tencentcloud-sdk-python python-telegram-bot
import html2text
import re
import imaplib
import email
import pdfplumber
import tempfile
from email.header import decode_header
import logging
import sys
import os
from bs4 import BeautifulSoup
from md2tgmd import escape
from dotenv import load_dotenv
import asyncio
from tencentcloud.common import credential
from tencentcloud.common.profile.http_profile import HttpProfile
from tencentcloud.common.profile.client_profile import ClientProfile
from tencentcloud.tmt.v20180321 import tmt_client, models
from pathlib import Path
from telegram import Bot
from telegram.constants import ParseMode
# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è·å–å½“å‰è„šæœ¬æ‰€åœ¨çš„ç»å¯¹ç›®å½•
current_dir = Path(__file__).parent.absolute()
log_file_path = current_dir / "mail.log"

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file_path),
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)
telegram_bot_logger = logging.getLogger('telegram.bot')
telegram_bot_logger.setLevel(logging.WARNING)
urllib3_logger = logging.getLogger('urllib3.connectionpool')
urllib3_logger.setLevel(logging.WARNING)
telegram_ext_logger = logging.getLogger('telegram.ext')
telegram_ext_logger.setLevel(logging.WARNING)
# logger.info(f"æ—¥å¿—æ–‡ä»¶è·¯å¾„: {log_file_path}")

# ç¿»è¯‘é…ç½®
ENABLE_TRANSLATION = os.getenv('ENABLE_TRANSLATION', 'false').lower() == 'true'
TENCENTCLOUD_SECRET_ID = os.getenv('TENCENTCLOUD_SECRET_ID')
TENCENTCLOUD_SECRET_KEY = os.getenv('TENCENTCLOUD_SECRET_KEY')
TENCENT_REGION = os.getenv('TENCENT_REGION', 'ap-beijing')

class AdvancedHTMLPreprocessor:
    """ä½¿ç”¨BeautifulSoupçš„é«˜çº§HTMLé¢„å¤„ç†å™¨"""
    
    def __init__(self):
        self.removed_elements_count = 0
        
    def preprocess_html(self, html_content):
        """
        å®Œæ•´çš„HTMLé¢„å¤„ç†æµç¨‹
        """
        if not html_content or not html_content.strip():
            return ""
            
        try:
            soup = BeautifulSoup(html_content, 'html5lib')
            
            # è®°å½•åˆå§‹çŠ¶æ€
            initial_length = len(str(soup))
            
            # æ‰§è¡Œé¢„å¤„ç†æ­¥éª¤
            self._remove_empty_links(soup)  # æ–°å¢ï¼šå…ˆç§»é™¤ç©ºé“¾æ¥
            self._remove_unwanted_elements(soup)
            self._remove_empty_elements(soup)
            self._clean_attributes(soup)
            self._preserve_line_breaks(soup)
            self._optimize_structure(soup)
            
            # è·å–å¤„ç†åçš„HTML
            processed_html = str(soup)
            
            # æœ€ç»ˆæ¸…ç†
            processed_html = self._final_cleanup(processed_html)
            
            # è®°å½•å¤„ç†æ•ˆæœ
        #    final_length = len(processed_html)
         #   reduction = ((initial_length - final_length) / initial_length) * 100
        #    logging.info(f"HTMLé¢„å¤„ç†: é•¿åº¦ä» {initial_length} å‡å°‘åˆ° {final_length} ({reduction:.1f}% å‡å°‘)")
       #     logging.info(f"ç§»é™¤äº† {self.removed_elements_count} ä¸ªæ— ç”¨å…ƒç´ ")
            
            return processed_html
            
        except Exception as e:
            logging.error(f"HTMLé¢„å¤„ç†å¤±è´¥: {e}")
            return html_content
    
    def _remove_empty_links(self, soup):
        """ç§»é™¤ç©ºçš„æˆ–åªæœ‰ç©ºç™½å­—ç¬¦çš„é“¾æ¥"""
        links = soup.find_all('a')
        
        for link in links:
            # è·å–é“¾æ¥æ–‡æœ¬å†…å®¹ï¼ˆä¸åŒ…æ‹¬å­å…ƒç´ ï¼‰
            link_text = link.get_text(strip=True)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºé“¾æ¥æˆ–åªæœ‰ä¸å¯è§å­—ç¬¦
            is_empty_link = (
                not link_text or  # å®Œå…¨ç©ºæ–‡æœ¬
                link_text.isspace() or  # åªæœ‰ç©ºç™½å­—ç¬¦
                len(link_text.strip()) == 0 or  # æ¸…ç†åä¸ºç©º
                link_text in ['.', '-', 'Â·', 'â€¢']  # æ— æ„ä¹‰çš„å•ä¸ªå­—ç¬¦
            )
            
            # æ£€æŸ¥æ˜¯å¦åªæœ‰å›¾ç‰‡ä½†æ— æ–‡æœ¬
            has_only_img = len(link.find_all()) == 1 and link.find('img') and not link_text
            
            # æ£€æŸ¥hrefæ˜¯å¦ä¸ºç©ºæˆ–æ— æ•ˆ
            href = link.get('href', '')
            is_invalid_href = (
                not href or
                href.startswith(('javascript:', 'mailto:')) or
                href == '#' or
                href.strip() == ''
            )
            
            if is_empty_link or has_only_img or is_invalid_href:
                # ç§»é™¤è¿™ä¸ªç©ºé“¾æ¥ï¼Œä½†ä¿ç•™æ–‡æœ¬å†…å®¹
                link.unwrap()  # ä½¿ç”¨unwrap()è€Œä¸æ˜¯decompose()æ¥ä¿ç•™æ–‡æœ¬
                self.removed_elements_count += 1
            #    logging.debug(f"ç§»é™¤äº†ç©ºé“¾æ¥: {href}")
    
    def _remove_unwanted_elements(self, soup):
        """ç§»é™¤ä¸éœ€è¦çš„HTMLå…ƒç´ """
        unwanted_selectors = [
            'script', 'style', 'noscript', 'meta', 'link', 'head',
            'iframe', 'object', 'embed', 'applet',
            'form', 'input', 'button', 'select', 'textarea',
            'nav', 'footer', 'header', 'aside',
        ]
        
        for selector in unwanted_selectors:
            elements = soup.find_all(selector)
            self.removed_elements_count += len(elements)
            for element in elements:
                element.decompose()

    def _remove_empty_elements(self, soup):
        """ç§»é™¤ç©ºçš„æˆ–åªæœ‰ç©ºç™½å­—ç¬¦çš„å…ƒç´ """
        # æ£€æŸ¥è¿™äº›æ ‡ç­¾æ˜¯å¦ä¸ºç©º
        tags_to_check = ['p', 'div', 'span', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 
                        'td', 'th', 'li', 'ul', 'ol', 'section', 'article']
        
        for tag in tags_to_check:
            elements = soup.find_all(tag)
            for element in elements:
                # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºæˆ–åªæœ‰ç©ºç™½å­—ç¬¦
                text_content = element.get_text(strip=True)
                has_visible_children = bool(element.find_all(True))
                
                if not text_content and not has_visible_children:
                    element.decompose()
                    self.removed_elements_count += 1
                elif text_content and len(text_content.strip()) < 2:  # åªæœ‰1-2ä¸ªå­—ç¬¦
                    # æ£€æŸ¥çˆ¶å…ƒç´ ï¼Œå¦‚æœçˆ¶å…ƒç´ æœ‰å…¶ä»–å†…å®¹åˆ™ç§»é™¤è¿™ä¸ªç©ºå…ƒç´ 
                    parent = element.parent
                    if parent and len(parent.get_text(strip=True)) > len(text_content):
                        element.decompose()
                        self.removed_elements_count += 1
    
    def _clean_attributes(self, soup):
        """æ¸…ç†HTMLå±æ€§ï¼Œä¿ç•™å¿…è¦çš„"""
        for tag in soup.find_all(True):  # True åŒ¹é…æ‰€æœ‰æ ‡ç­¾
            attrs_to_remove = []
            
            for attr in tag.attrs:
                # ç§»é™¤æ ·å¼ç›¸å…³å±æ€§
                if attr in ['style', 'class', 'id']:
                    attrs_to_remove.append(attr)
                # ç§»é™¤äº‹ä»¶å¤„ç†å™¨
                elif attr.startswith('on'):
                    attrs_to_remove.append(attr)
                # ç§»é™¤æ•°æ®å±æ€§ï¼ˆé€šå¸¸ç”¨äºJavaScriptï¼‰
                elif attr.startswith('data-'):
                    attrs_to_remove.append(attr)
                # ç§»é™¤ä¸€äº›ç‰¹å®šçš„å±æ€§
                elif attr in ['width', 'height', 'border', 'cellpadding', 'cellspacing']:
                    attrs_to_remove.append(attr)
            
            # ç§»é™¤å±æ€§
            for attr in attrs_to_remove:
                del tag[attr]
            
            # å¯¹äºé“¾æ¥ï¼Œç¡®ä¿hrefå±æ€§å­˜åœ¨ä¸”æœ‰æ•ˆ
            if tag.name == 'a' and 'href' in tag.attrs:
                href = tag['href']
                # æ¸…ç†JavaScripté“¾æ¥
                if href.startswith(('javascript:', 'mailto:')):
                    # å°†é“¾æ¥è½¬æ¢ä¸ºçº¯æ–‡æœ¬
                    tag.replace_with(tag.get_text())
    
    def _preserve_line_breaks(self, soup):
        """ä¿æŠ¤é‡è¦çš„æ¢è¡Œç»“æ„"""
        # ä¿æŠ¤æ®µè½æ ‡ç­¾çš„æ¢è¡Œ
        for tag in soup.find_all(['p', 'div', 'br']):
            if tag.name == 'br':
                # ç¡®ä¿bræ ‡ç­¾åé¢æœ‰æ¢è¡Œ
                if tag.next_sibling and not str(tag.next_sibling).startswith('\n'):
                    tag.insert_after(soup.new_string('\n'))
            elif tag.name in ['p', 'div']:
                # ç¡®ä¿å—çº§å…ƒç´ å‰åæœ‰æ¢è¡Œ
                if tag.previous_sibling and not str(tag.previous_sibling).endswith('\n'):
                    tag.insert_before(soup.new_string('\n'))
                if tag.next_sibling and not str(tag.next_sibling).startswith('\n'):
                    tag.insert_after(soup.new_string('\n'))
    
    def _optimize_structure(self, soup):
        """ä¼˜åŒ–HTMLç»“æ„"""
        # ç§»é™¤åµŒå¥—è¿‡æ·±çš„div
        divs = soup.find_all('div')
        for div in divs:
            # å¦‚æœdivåªåŒ…å«ä¸€ä¸ªå­å…ƒç´ ä¸”ä¹Ÿæ˜¯divï¼Œå¯ä»¥è€ƒè™‘ç®€åŒ–
            children = div.find_all(recursive=False)
            if len(children) == 1 and children[0].name == 'div':
                children[0].unwrap()  # ç§»é™¤å¤–å±‚div
    
    def _final_cleanup(self, html_content):
        """æœ€ç»ˆæ¸…ç†"""
        # ç§»é™¤HTMLæ³¨é‡Š
        html_content = re.sub(r'<!--.*?-->', '', html_content, flags=re.DOTALL)
        
        # å»é™¤ --- æˆ–è€…å¤šä¸ª --- --- æ ¼å¼
        html_content = re.sub(r'---( ---)*', '', html_content)
        
        # å»é™¤ -- æˆ–è€…å¤šä¸ª -- -- æ ¼å¼  
        html_content = re.sub(r'--( --)*', '', html_content)
        
        # å»é™¤ -- æˆ–è€…å¤šä¸ª -- -- æ ¼å¼  
        html_content = re.sub(r'[Â·.]{3,}', 'Â·Â·', html_content)
        html_content = re.sub(r'^\s*\\+\s*$', '', html_content)
        
        # åˆ é™¤è¿ç»­çš„ ''''''ï¼ˆ6ä¸ªå•å¼•å·ï¼‰
        html_content = re.sub(r"'{6}", '', html_content)
        
        # ç²¾å‡†åˆ é™¤è¿ç»­çš„ ' s ' æ¨¡å¼
        # åŒ¹é…æ¨¡å¼ï¼š' s ' é‡å¤å‡ºç°ï¼Œä¸­é—´å¯èƒ½æœ‰æ¢è¡Œæˆ–ç©ºæ ¼
        html_content = re.sub(r"('\s*s\s*')+", '', html_content)
        
        return html_content.strip()

class EmailToTelegramBot:
    def __init__(self):
        """
        åˆå§‹åŒ– - ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        """
        # ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®
        self.email_config = {
            'imap_server': os.getenv('IMAP_SERVER', 'imap.qq.com'),
            'imap_port': 993,
            'email': os.getenv('EMAIL_USER'),
            'password': os.getenv('EMAIL_PASSWORD'),
            'ssl': True
        }
        
        # ä¿®æ”¹Telegramé…ç½®
        self.telegram_config = {
            'bot_token': os.getenv('TELEGRAM_API_KEY'),
            'chat_ids': self._parse_chat_ids(os.getenv('TELEGRAM_CHAT_ID', ''))
        }
        
        # åˆå§‹åŒ–Telegram Bot
        self.bot = Bot(token=self.telegram_config['bot_token'])
        
        # éªŒè¯å¿…è¦é…ç½®
        self._validate_config()
        
        # åˆå§‹åŒ–HTMLé¢„å¤„ç†å™¨
        self.html_preprocessor = AdvancedHTMLPreprocessor()
        
        # é…ç½®HTMLåˆ°Markdownè½¬æ¢å™¨
        self.h = html2text.HTML2Text()
        self.h.body_width = 0
        self.h.ignore_links = False
        self.h.ignore_images = True
        self.h.ignore_emphasis = False
        self.h.ignore_tables = False
        self.h.mark_code = True
            
    def _parse_chat_ids(self, chat_ids_str):
        """è§£æèŠå¤©IDï¼Œåªæ”¯æŒå•ä¸ªID"""
        if not chat_ids_str:
            logging.error("TELEGRAM_CHAT_ID ç¯å¢ƒå˜é‡ä¸ºç©º")
            return []
        
        # åªå–ç¬¬ä¸€ä¸ªIDï¼Œå¿½ç•¥é€—å·åˆ†éš”çš„å…¶ä»–ID
        chat_id = chat_ids_str.split(',')[0].strip()
        
        if not chat_id:
            logging.error("èŠå¤©IDæ ¼å¼é”™è¯¯")
            return []
        
        # æ¸…ç†èŠå¤©ID
        chat_id = str(chat_id).replace('"', '').replace("'", "").strip()
        
     #   logging.info(f"ä½¿ç”¨çš„èŠå¤©ID: {chat_id}")
        return [chat_id]
    
    def _validate_config(self):
        """éªŒè¯é…ç½®æ˜¯å¦å®Œæ•´"""
        missing_vars = []
        
        if not self.email_config['email']:
            missing_vars.append('EMAIL_USER')
        if not self.email_config['password']:
            missing_vars.append('EMAIL_PASSWORD')
        if not self.telegram_config['bot_token']:
            missing_vars.append('TELEGRAM_API_KEY')
        if not self.telegram_config['chat_ids']:
            missing_vars.append('TELEGRAM_CHAT_ID')
            
        if missing_vars:
            logging.error(f"ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
            logging.error("è¯·æ£€æŸ¥ .env æ–‡ä»¶é…ç½®")
            sys.exit(1)
        
    #   logging.info(f"é…ç½®éªŒè¯æˆåŠŸï¼Œå°†å‘é€åˆ° {len(self.telegram_config['chat_ids'])} ä¸ªèŠå¤©: {self.telegram_config['chat_ids']}")
    
    def connect_email(self):
        """è¿æ¥åˆ°é‚®ç®±æœåŠ¡å™¨"""
        try:
            if self.email_config['ssl']:
                mail = imaplib.IMAP4_SSL(self.email_config['imap_server'], self.email_config['imap_port'])
            else:
                mail = imaplib.IMAP4(self.email_config['imap_server'], self.email_config['imap_port'])
            
            mail.login(self.email_config['email'], self.email_config['password'])
       #     logging.info("é‚®ç®±ç™»å½•æˆåŠŸ")
            return mail
        except Exception as e:
            logging.error(f"é‚®ç®±è¿æ¥å¤±è´¥: {e}")
            return None
    
    def get_unread_emails(self, mail):
        """è·å–æœªè¯»é‚®ä»¶"""
        try:
            # é€‰æ‹©æ”¶ä»¶ç®±
            mail.select("INBOX")
            
            # æœç´¢æœªè¯»é‚®ä»¶
            status, messages = mail.search(None, 'UNSEEN')
            if status != 'OK':
         #       logging.info("æ²¡æœ‰æ‰¾åˆ°æœªè¯»é‚®ä»¶")
                return []
            
            email_ids = messages[0].split()
        #    logging.info(f"æ‰¾åˆ° {len(email_ids)} å°æœªè¯»é‚®ä»¶")
            return email_ids
        except Exception as e:
            logging.error(f"è·å–æœªè¯»é‚®ä»¶å¤±è´¥: {e}")
            return []
    
    def decode_mime_words(self, text):
        """è§£ç é‚®ä»¶å¤´"""
        if text is None:
            return ""
        decoded_parts = decode_header(text)
        decoded_text = ""
        for part, encoding in decoded_parts:
            if isinstance(part, bytes):
                if encoding:
                    decoded_text += part.decode(encoding)
                else:
                    decoded_text += part.decode('utf-8', errors='ignore')
            else:
                decoded_text += part
        return decoded_text
    
    def extract_email_content(self, msg):
        """æå–é‚®ä»¶å†…å®¹"""
        subject = self.decode_mime_words(msg.get("Subject", "æ— ä¸»é¢˜"))
        from_ = self.decode_mime_words(msg.get("From", "æœªçŸ¥å‘ä»¶äºº"))
        date = msg.get("Date", "æœªçŸ¥æ—¥æœŸ")
        
        # æå–é‚®ä»¶æ­£æ–‡
        html_content = ""
        plain_content = ""
        
        if msg.is_multipart():
            for part in msg.walk():
                content_type = part.get_content_type()
                content_disposition = str(part.get("Content-Disposition"))
                
                # è·³è¿‡é™„ä»¶
                if "attachment" in content_disposition:
                    continue
                    
                if content_type == "text/plain" and not plain_content:
                    try:
                        body = part.get_payload(decode=True)
                        charset = part.get_content_charset() or 'utf-8'
                        plain_content = body.decode(charset, errors='ignore')
                    except Exception as e:
                        logging.warning(f"è§£æçº¯æ–‡æœ¬å†…å®¹å¤±è´¥: {e}")
                
                elif content_type == "text/html" and not html_content:
                    try:
                        body = part.get_payload(decode=True)
                        charset = part.get_content_charset() or 'utf-8'
                        html_content = body.decode(charset, errors='ignore')
                    except Exception as e:
                        logging.warning(f"è§£æHTMLå†…å®¹å¤±è´¥: {e}")
        else:
            # å•éƒ¨åˆ†é‚®ä»¶
            content_type = msg.get_content_type()
            body = msg.get_payload(decode=True)
            charset = msg.get_content_charset() or 'utf-8'
            
            try:
                if content_type == "text/plain":
                    plain_content = body.decode(charset, errors='ignore')
                elif content_type == "text/html":
                    html_content = body.decode(charset, errors='ignore')
            except Exception as e:
                logging.warning(f"è§£æé‚®ä»¶å†…å®¹å¤±è´¥: {e}")
        
        return {
            'subject': subject,
            'from': from_,
            'date': date,
            'html_content': html_content,
            'plain_content': plain_content
        }
    
    def convert_email_to_markdown(self, email_data):
        """å°†é‚®ä»¶å†…å®¹è½¬æ¢ä¸ºMarkdownæ ¼å¼"""
        subject = email_data['subject']
        from_ = email_data['from']
        date = email_data['date']
        
        # è§£æå‘ä»¶äººä¿¡æ¯
        from_name, from_email = self._parse_sender_info(from_)
        
        # å¤„ç†ç”¨æˆ·åä¸­çš„ç‚¹å·
        if from_name:
            from_name = from_name.replace('.', '.\u200c')
        
        # å¤„ç†ä¸»é¢˜ï¼šæ¸…ç†ä¸‹åˆ’çº¿å¹¶æ›¿æ¢ç‚¹å·
        if subject:
            subject = subject.replace('_', 'Ë')  # æ¸…ç†ä¸‹åˆ’çº¿
            subject = subject.replace('.', '.\u200c')  # æ›¿æ¢ç‚¹å·
            subject = subject.replace(r'\\', ' ') # å»é™¤è¿ç»­çš„åæ–œæ 

        # å¤„ç†é‚®ç®±åœ°å€ï¼šå»é™¤åæ–œæ 
        if from_email:
            from_email = from_email.replace('\\', ' ')  # å»é™¤åæ–œæ 
            
        # ä¼˜å…ˆä½¿ç”¨HTMLå†…å®¹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨çº¯æ–‡æœ¬
        if email_data['html_content']:
            # åœ¨è½¬æ¢å‰å…ˆé¢„å¤„ç†HTMLï¼ˆåŒ…æ‹¬ç§»é™¤ç©ºé“¾æ¥ï¼‰
            content = self.convert_html_to_markdown(email_data['html_content'])
        elif email_data['plain_content']:
            content = email_data['plain_content']
        else:
            content = "ã€æ­¤é‚®ä»¶æ— æ­£æ–‡å†…å®¹ã€‘"
        
        # æ£€æµ‹æ˜¯å¦éœ€è¦ç¿»è¯‘
        need_translation = ENABLE_TRANSLATION and not self.is_mainly_chinese(content)
        
        if need_translation:
       #     logging.info("æ£€æµ‹åˆ°éä¸­æ–‡å†…å®¹ï¼Œå¼€å§‹å®‰å…¨ç¿»è¯‘...")
            try:
                # ç¿»è¯‘ä¸»é¢˜ - ä½¿ç”¨å®‰å…¨ç¿»è¯‘
                translated_subject = self.translate_content_sync_safe(subject)
                if translated_subject and translated_subject != subject:
                    subject = translated_subject
               #     logging.info("ä¸»é¢˜å®‰å…¨ç¿»è¯‘å®Œæˆ")
                
                # ç¿»è¯‘å†…å®¹ - ä½¿ç”¨å®‰å…¨ç¿»è¯‘
                translated_content = self.translate_content_sync_safe(content)
                if translated_content and translated_content != content:
                    content = translated_content.replace('_', 'Ë')
               #     logging.info("å†…å®¹å®‰å…¨ç¿»è¯‘å®Œæˆ")
                
            except Exception as e:
                logging.error(f"å®‰å…¨ç¿»è¯‘å¤±è´¥: {e}")
                # ç¿»è¯‘å¤±è´¥æ—¶ä¿ç•™åŸæ–‡
        
        # æ„å»ºç¬¦åˆè¦æ±‚çš„Markdownæ¶ˆæ¯æ ¼å¼
        markdown_message = ""
        
        # ç”¨æˆ·åï¼ˆç²—ä½“ï¼‰
        if from_name:
            markdown_message += f"**{from_name}**"
        
        # é‚®ç®±åœ°å€ï¼ˆç­‰å®½ï¼‰
        if from_email:
            if from_name:
                markdown_message += " "  # ç”¨æˆ·åå’Œé‚®ç®±ä¹‹é—´åŠ ç©ºæ ¼
            markdown_message += f"`{from_email}`"
        
        markdown_message += "\n"
        
        # ä¸»é¢˜ï¼ˆæ–œä½“ï¼‰
        if subject:
            markdown_message += f"_{subject}_\n\n"

        # å†…å®¹
        markdown_message += content
        
        return markdown_message

    def convert_html_to_markdown(self, html_content):
        """å°†HTMLè½¬æ¢ä¸ºMarkdown"""
        if not html_content:
            return ""
        
        # 1. é¢„å¤„ç†HTMLï¼ˆè¿™é‡Œå·²ç»åŒ…å«äº†ç§»é™¤ç©ºé“¾æ¥ï¼‰
        cleaned_html = self.html_preprocessor.preprocess_html(html_content)
        
        # 2. è½¬æ¢ä¸ºMarkdown
        markdown = self.h.handle(cleaned_html)
        
        # 4. åå¤„ç†Markdown - ç¡®ä¿è¿™é‡ŒåŒ…å«äº†ç©ºé“¾æ¥æ¸…ç†
        final_markdown = self.postprocess_markdown(markdown)
        
        # 5. æœ€ç»ˆçš„ç©ºé“¾æ¥æ¸…ç†ï¼ˆç¡®ä¿ä¸‡æ— ä¸€å¤±ï¼‰
        final_markdown = self.final_clean_empty_links(final_markdown)
        
        # 6. å¤„ç†æ˜Ÿå·ï¼šä¿ç•™å¼€å¤´çš„*ï¼Œä¿ç•™**ï¼Œåˆ é™¤å•ç‹¬çš„*
        final_markdown = self.process_asterisks(final_markdown)
        # æ–°å¢ï¼šå®‰å…¨æ›¿æ¢ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿æŠ¤URLã€é‚®ç®±ç­‰æ ¼å¼ï¼‰
       # markdown = self.replace_special_chars_safely(markdown)
        # 7. æ–°å¢ï¼šå°†ç‚¹å·æ›¿æ¢ä¸ºå…¨è§’ç‚¹å·+Emç©ºæ ¼ï¼ˆæ’é™¤URLå’Œç­‰ä½“å­—ï¼‰
    #    final_markdown = self.replace_dots_safely(final_markdown)
        return final_markdown
    
    def replace_dots_safely(self, text):
        """
        å®‰å…¨æ›¿æ¢ç‚¹å·å’Œ@ç¬¦å·ï¼Œä¿æŠ¤ç‰¹å®šæ ¼å¼
        """
        if not text:
            return text
        
        def replace_unprotected_chars(match):
            content = match.group(0)
            
            # æ‰©å±•ä¿æŠ¤åŒºåŸŸåˆ¤æ–­
            if (content.startswith(('http://', 'https://', 'ftp://')) or  # å„ç§URL
                content.startswith('[') and '](' in content and content.endswith(')') or  # Markdowné“¾æ¥
                content.startswith('`') and content.endswith('`') or  # è¡Œå†…ä»£ç 
                content.startswith('```') and content.endswith('```') or  # ä»£ç å—
                re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$', content)):  # é‚®ç®±åœ°å€
                return content
            
            # åªæœ‰å½“å†…å®¹ç¡®å®åŒ…å«ç‚¹å·æ—¶æ‰æ›¿æ¢
            if '.' in content:
                content = content.replace('.', '.\u200c')

            return content
        
        # æ›´ç²¾ç¡®çš„æ¨¡å¼ï¼šåªåŒ¹é…å¯èƒ½åŒ…å«ç‚¹å·çš„æ–‡æœ¬ç‰‡æ®µ
        pattern = r'https?://[^\s]+|ftp://[^\s]+|\[[^\]]+\]\([^)]+\)|`[^`]+`|```[^`]+```|[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}|[^\s]+'
        
        # å…ˆè¿›è¡Œç‰¹æ®Šå­—ç¬¦æ›¿æ¢
        text = re.sub(pattern, replace_unprotected_chars, text)
        
        return text
    
    def process_asterisks(self, text):
        """
        å¤„ç†æ˜Ÿå·ï¼šå¦‚æœå¼€å¤´æ˜¯*å°±ä¿ç•™ï¼Œä¿ç•™**è¿ç»­çš„æ˜Ÿå·ï¼Œåˆ é™¤å•ç‹¬çš„*
        
        Args:
            text: è¾“å…¥çš„æ–‡æœ¬
            
        Returns:
            å¤„ç†åçš„æ–‡æœ¬
        """
        if not text:
            return text
        
        lines = text.split('\n')
        processed_lines = []
        
        for line in lines:
            # å¤„ç†å¼€å¤´æ˜¯*çš„æƒ…å†µï¼ˆå¦‚åˆ—è¡¨é¡¹ï¼‰
            if line.strip().startswith('*'):
                # ä¿ç•™å¼€å¤´çš„*ï¼Œä½†å¤„ç†è¡Œå†…å•ç‹¬çš„*
                processed_line = self._process_line_asterisks(line)
            else:
                # å¤„ç†æ•´è¡Œä¸­çš„å•ç‹¬*
                processed_line = self._process_line_asterisks(line)
            
            processed_lines.append(processed_line)
        
        # å¤„ç†å®Œæˆåï¼Œæ£€æŸ¥æ˜¯å¦æœ‰è¡Œåªæœ‰è¿ç»­çš„æ˜Ÿå·ï¼ˆè‡³å°‘1ä¸ªï¼‰
        final_lines = []
        for line in processed_lines:
            stripped_line = line.strip()
            # å¦‚æœä¸€è¡Œä¹‹ä¸­åªæœ‰è¿ç»­çš„æ˜Ÿå·ï¼ˆè‡³å°‘1ä¸ªï¼‰ï¼Œå°±åˆ é™¤æ˜Ÿå·ä½†ä¿ç•™ç©ºè¡Œ
            if stripped_line and all(c == '*' for c in stripped_line):
                final_lines.append('')  # åˆ é™¤æ˜Ÿå·ä½†ä¿ç•™ç©ºè¡Œ
            else:
                final_lines.append(line)
        
        return '\n'.join(final_lines)

    def _process_line_asterisks(self, line):
        """
        å¤„ç†å•è¡Œä¸­çš„æ˜Ÿå·
        
        Args:
            line: å•è¡Œæ–‡æœ¬
            
        Returns:
            å¤„ç†åçš„å•è¡Œæ–‡æœ¬
        """
        if not line or '*' not in line:
            return line
        
        # ç”¨äºæ„å»ºç»“æœ
        result = []
        i = 0
        length = len(line)
        
        while i < length:
            if line[i] == '*':
                # æ£€æŸ¥æ˜¯å¦æ˜¯è¿ç»­çš„**
                if i + 1 < length and line[i + 1] == '*':
                    # ä¿ç•™**
                    result.append('**')
                    i += 2
                else:
                    # å•ç‹¬çš„*ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦ä¿ç•™
                    # å¦‚æœæ˜¯è¡Œé¦–çš„*ï¼ˆå‰é¢åªæœ‰ç©ºæ ¼ï¼‰ï¼Œåˆ™ä¿ç•™
                    if i == 0 or (i > 0 and all(c == ' ' for c in line[:i])):
                        result.append('*')
                        i += 1
                    else:
                        # åˆ é™¤å•ç‹¬çš„*
                        i += 1
            else:
                result.append(line[i])
                i += 1
        
        return ''.join(result)

    def final_clean_empty_links(self, markdown):
        """æœ€ç»ˆçš„ç©ºé“¾æ¥æ¸…ç†"""
        if not markdown:
            return ""
        
        # å¤šæ¬¡æ¸…ç†ç¡®ä¿æ²¡æœ‰æ¼ç½‘ä¹‹é±¼
        patterns = [
            r'\[\s*\]\s*\([^)]*\)',  # []()
            r'\[\s+\]\s*\([^)]*\)',  # [   ]()
            r'\[([.\-\s]{1,2})\]\s*\([^)]*\)',  # [.]()ã€[-]()ç­‰
        ]
        
        for pattern in patterns:
            markdown = re.sub(pattern, '', markdown)
        
        return markdown
    
    def _parse_sender_info(self, sender_string):
        """è§£æå‘ä»¶äººä¿¡æ¯ï¼Œè¿”å›(å§“å, é‚®ç®±)"""
        if not sender_string:
            return "", ""
        
        try:
            # ä½¿ç”¨email.utils.parseaddrè§£æå‘ä»¶äººä¿¡æ¯
            from email.utils import parseaddr
            name, email_addr = parseaddr(sender_string)
            
            # æ¸…ç†å§“åä¸­çš„ç‰¹æ®Šå­—ç¬¦
            if name:
                name = re.sub(r'[<>]', '', name).strip()
            
            # å¦‚æœæ²¡æœ‰å§“åï¼Œå°è¯•ä»é‚®ç®±ä¸­æå–ç”¨æˆ·å
            if not name and email_addr:
                name = email_addr.split('@')[0]
                
            return name, email_addr
            
        except Exception as e:
            logging.warning(f"è§£æå‘ä»¶äººä¿¡æ¯å¤±è´¥: {e}")
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²ä½œä¸ºå§“å
            return sender_string, ""
    
    def clean_special_characters(self, text):
        """å†…å®¹æ¸…ç†ç‰¹æ®Šå­—ç¬¦ï¼š| å’Œ ---ï¼Œç¡®ä¿ä¿ç•™æ¢è¡Œç¬¦"""
        if not text:
            return ""
        # æ›¿æ¢ _ ä¸ºç±»ä¼¼å­—ç¬¦ï¼Œé¿å…ä¸Markdownè¯­æ³•å†²çª
        text = text.replace(r'_', 'Ë')
        text = text.replace('\\', ' ')
        text = re.sub(r'#+', '# ', text)
        # æ¸…ç† | ç¬¦å·
        text = re.sub(r'(?<!\|)\|(?!\|)', ' ', text)

        # æŒ‰è¡Œå¤„ç†
        lines = text.split('\n')
        processed_lines = []

        for line in lines:
            # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ†éš”çº¿
            is_separator = (
                re.match(r'^\s*-{3,}\s*$', line) or
                re.match(r'^\s*â€”{1,}\s*$', line) or
                re.match(r'^\s*(-\s*){2,}$', line) or
                re.match(r'^\s*(-\s*){3,}$', line)
            )
        
            if is_separator:
                processed_lines.append("")
            else:
                # æ¸…ç†è¡Œé¦–çš„æ¨ªçº¿
                cleaned_line = re.sub(r'^\s*(-\s*){2,}', '', line)
                cleaned_line = re.sub(r'^\s*â€”+\s*', '', cleaned_line)
                processed_lines.append(cleaned_line)

        # é‡æ–°ç»„åˆ
        result = '\n'.join(processed_lines)
        
        return result
    
    def normalize_whitespace(self, text):
        """æ ‡å‡†åŒ–ç©ºç™½å­—ç¬¦ï¼Œç¡®ä¿è¿ç»­ç©ºè¡Œæœ€å¤š2ä¸ª"""
        if not text:
            return ""
        
        # 1. é¦–å…ˆæ ‡å‡†åŒ–æ¢è¡Œç¬¦
        text = re.sub(r'\r\n', '\n', text)
        text = re.sub(r'\r', '\n', text)
        
        # 2. æ¸…ç†ç‰¹æ®Šå­—ç¬¦
        text = self.clean_special_characters(text)
        
        # 3. å…³é”®æ­¥éª¤ï¼šæŠŠæ‰€æœ‰3ä¸ªåŠä»¥ä¸Šçš„è¿ç»­æ¢è¡Œï¼ˆåŒ…æ‹¬ä¸­é—´æœ‰ç©ºç™½å­—ç¬¦çš„ï¼‰æ›¿æ¢ä¸º2ä¸ªæ¢è¡Œ
        text = re.sub(r'(\n\s*){3,}', '\n\n', text)

        # 4. æŒ‰è¡Œå¤„ç†ï¼Œæ¸…ç†è¡Œé¦–è¡Œå°¾ç©ºæ ¼
        lines = text.split('\n')
        processed_lines = []
        
        for line in lines:
            stripped_line = line.strip()
            processed_lines.append(stripped_line)
        
        # 5. é‡æ–°ç»„åˆ
        result = '\n'.join(processed_lines)
        
        return result
    
    def postprocess_markdown(self, markdown):
        """åå¤„ç†Markdownå†…å®¹ - ä¼˜åŒ–ç©ºè¡Œå’Œç‰¹æ®Šå­—ç¬¦å¤„ç†"""
        if not markdown:
            return ""

        # æ¸…ç†ç‰¹æ®Šå­—ç¬¦å’Œæ ‡å‡†åŒ–ç©ºç™½
        markdown = self.normalize_whitespace(markdown)
        # æ–°å¢ï¼šåˆ é™¤æ•´è¡Œéƒ½æ˜¯ä¸å¯è§å­—ç¬¦çš„è¡Œ
        markdown = self.remove_invisible_lines(markdown)

        # æ–°å¢ï¼šä¸“é—¨æ¸…ç†ç©ºæ–‡æœ¬çš„Markdowné“¾æ¥
        markdown = self.remove_empty_markdown_links(markdown)
        
        # æ–°å¢ï¼šç§»é™¤è¶…é•¿URL
        markdown = self.remove_long_urls(markdown)
        
        # æ–°å¢ï¼šå°†é‚®ç®±åœ°å€è½¬æ¢ä¸ºç­‰å®½å­—ä½“
        markdown = self.format_email_addresses(markdown)
        
        # æ–°å¢ï¼šæ¸…ç†åºå·é—´çš„ç©ºè¡Œï¼ˆä¿æŒç‹¬ç«‹åŠŸèƒ½ï¼‰
        #  markdown = self.remove_blank_lines_between_sequences(markdown)

        # æ–°å¢ï¼šå»é™¤ç©ºçš„ [] å’Œ () ç»„åˆ
        markdown = self.remove_empty_brackets(markdown)

        return markdown

    def remove_empty_brackets(self, text):
        """
        å»é™¤ç©ºçš„ []ã€()ã€{} ç­‰å„ç§æ‹¬å·ç»„åˆ
        """
        if not text:
            return text
        
        # å®šä¹‰å„ç§ç©ºæ‹¬å·æ¨¡å¼
        empty_bracket_patterns = {
            'square': (r'\[\s*\]', '[]'),      # æ–¹æ‹¬å·
            'round': (r'\(\s*\)', '()'),       # åœ†æ‹¬å·
            'curly': (r'\{\s*\}', '{}'),       # èŠ±æ‹¬å·
            'angle': (r'\<\s*\>', '<>'),       # å°–æ‹¬å·
            'single_quote': (r"'\s*'", "''"),  # å•å¼•å·
            'double_quote': (r'"\s*"', '""'),  # åŒå¼•å·
        }
        
        result = text
        removal_stats = {}
        
        for bracket_type, (pattern, display_name) in empty_bracket_patterns.items():
            count_before = len(re.findall(pattern, result))
            if count_before > 0:
                result = re.sub(pattern, '', result)
                removal_stats[display_name] = count_before
        
        # è®°å½•æ¸…ç†æ•ˆæœ
        if removal_stats:
            stats_str = ', '.join([f'{name} {count}ä¸ª' for name, count in removal_stats.items()])
        #    logging.info(f"æ¸…ç†ç©ºæ‹¬å·ç»„åˆ: ç§»é™¤ {stats_str}")
        
        return result

    
    def format_email_addresses(self, text):
        """
        å°†é‚®ç®±åœ°å€ç”¨ç­‰å®½å­—ä½“æ ‡è®°ï¼Œä½†ä¸å¤„ç†URL
        """
        if not text:
            return text
        
        # é‚®ç®±åœ°å€æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        
        def wrap_email_in_monospace(match):
            email = match.group(0)
            return f'`{email}`'
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢é‚®ç®±åœ°å€
        text = re.sub(email_pattern, wrap_email_in_monospace, text)
        
        # åˆ é™¤URLåŒ…è£…ä¸ºç­‰ä½“å­—çš„åŠŸèƒ½
        # åŸæ¥çš„URLå¤„ç†ä»£ç å·²ç§»é™¤
        
        return text

    def fix_url_format(self, url):
        """
        ä¿®å¤URLæ ¼å¼ï¼ˆåªæœ‰è¢«æ ‡è®°ä¸ºç­‰å®½å­—ä½“çš„å•ç‹¬URLæ‰ä¼šè°ƒç”¨æ­¤å‡½æ•°ï¼‰ï¼š
        1. ç»Ÿä¸€è‹±æ–‡å­—ç¬¦ï¼ˆä¸­æ–‡å†’å·è½¬è‹±æ–‡ï¼‰
        2. è¡¥å…¨ç¼ºå¤±çš„//
        3. åˆ é™¤ç©ºæ ¼
        4. ç¡®ä¿åè®®å®Œæ•´
        """
        if not url:
            return url
        
        original_url = url
        
        try:
            # 1. åˆ é™¤æ‰€æœ‰ç©ºæ ¼
            url = re.sub(r'\s+', '', url)
            
            # 2. ç»Ÿä¸€è‹±æ–‡å­—ç¬¦ï¼šä¸­æ–‡å†’å·è½¬è‹±æ–‡å†’å·
            url = url.replace('ï¼š', ':')
            
            # 3. è¡¥å…¨åè®®å’Œ//
            if url.startswith('http'):
                # å¤„ç† http:example.com -> http://example.com
                if re.match(r'https?:[^/]', url):
                    url = url.replace(':', '://', 1)
                # å¤„ç† http:/example.com -> http://example.com  
                elif re.match(r'https?:/[^/]', url):
                    url = url.replace(':/', '://', 1)
                # å¤„ç† http//example.com -> http://example.com
                elif re.match(r'https?//', url):
                    url = url.replace('//', '://', 1)
            
            # 4. ç‰¹æ®Šå¤„ç†racknerd.comç›¸å…³URL
            if 'racknerd' in url.lower():
                # ç¡®ä¿racknerdåŸŸåå®Œæ•´
                url = re.sub(r'racknerd\s*\.\s*com', 'racknerd.com', url, flags=re.IGNORECASE)
                # å¤„ç†affå‚æ•°
                url = re.sub(r'aff\s*=\s*(\d+)', r'aff=\1', url, flags=re.IGNORECASE)
                # å¤„ç†aff.php? affæ ¼å¼
                url = re.sub(r'aff\.php\?\s*aff', 'aff.php?aff', url, flags=re.IGNORECASE)
            
       #     logging.debug(f"URLä¿®å¤: {original_url} -> {url}")
            return url
            
        except Exception as e:
            logging.warning(f"URLä¿®å¤å¤±è´¥ {original_url}: {e}")
            return original_url
    
    def remove_long_urls(self, text, max_url_length=300):  # é™ä½åˆ°300å­—ç¬¦æ›´å®‰å…¨
        """
        å¢å¼ºç‰ˆURLæ¸…ç† - æ›´å½»åº•åœ°ç§»é™¤é•¿é“¾æ¥
        """
        if not text:
            return text
        
        def replace_long_markdown_link(match):
            link_text = match.group(1)
            url = match.group(2)
            
            url_length = len(url)
            if url_length > max_url_length:
            #    logging.info(f"ğŸš« ç§»é™¤è¶…é•¿Markdowné“¾æ¥: {url[:30]}... (é•¿åº¦: {url_length})")
                return link_text  # åªä¿ç•™é“¾æ¥æ–‡æœ¬
            else:
                return match.group(0)  # ä¿ç•™å®Œæ•´é“¾æ¥
        
        def replace_long_plain_url(match):
            url = match.group(0)
            url_length = len(url)
            if url_length > max_url_length:
      #          logging.info(f"ğŸš« ç§»é™¤è¶…é•¿çº¯æ–‡æœ¬URL: {url[:30]}... (é•¿åº¦: {url_length})")
                return ""  # å®Œå…¨ç§»é™¤
            else:
                return url  # ä¿ç•™
        
        # å¢å¼ºçš„URLåŒ¹é…æ¨¡å¼
        url_patterns = [
            # Markdowné“¾æ¥ [æ–‡æœ¬](URL)
            (r'\[([^\]]+)\]\(([^)]+)\)', replace_long_markdown_link),
            
            # çº¯æ–‡æœ¬URLï¼ˆæ›´å…¨é¢çš„åŒ¹é…ï¼‰
            (r'https?://[^\s<>"{}|\\^`\[\]()]{10,}', replace_long_plain_url),
            
            # æ²¡æœ‰åè®®çš„URLï¼ˆå¦‚ www.example.com/pathï¼‰
            (r'www\.[^\s<>"{}|\\^`\[\]()]{10,}', replace_long_plain_url),
        ]
        
        # å¤šæ¬¡å¤„ç†ç¡®ä¿æ²¡æœ‰æ¼ç½‘ä¹‹é±¼
        for pattern, replacement_func in url_patterns:
            text = re.sub(pattern, replacement_func, text)
        
        return text
    
    def remove_invisible_lines(self, text):
        """
        åˆ é™¤æ•´è¡Œä¸­çš„ä¸å¯è§å­—ç¬¦ï¼Œä½†ä¿ç•™è¡Œç»“æ„
        
        Args:
            text: è¾“å…¥çš„æ–‡æœ¬
            
        Returns:
            å¤„ç†åçš„æ–‡æœ¬
        """
        if not text:
            return text
        
        lines = text.split('\n')
        processed_lines = []
        
        # ä¸å¯è§å­—ç¬¦çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        invisible_chars = r'[\s\u034f\u00ad\u200b\u200c\u200d\u2060\u0000-\u001f\u007f-\u009f]'
        invisible_pattern = re.compile(f'^{invisible_chars}*$')
        
        for line in lines:
            # æ£€æŸ¥æ•´è¡Œæ˜¯å¦åªåŒ…å«ä¸å¯è§å­—ç¬¦æˆ–ç©ºç™½å­—ç¬¦
            if invisible_pattern.match(line):
                # å¦‚æœæ•´è¡Œéƒ½æ˜¯ä¸å¯è§å­—ç¬¦ï¼Œæ›¿æ¢ä¸ºç©ºè¡Œï¼ˆä¿ç•™è¡Œç»“æ„ï¼‰
                processed_lines.append("")
            else:
                # å¦‚æœè¡Œä¸­æœ‰å¯è§å†…å®¹ï¼Œåªåˆ é™¤ä¸å¯è§å­—ç¬¦ä½†ä¿ç•™å¯è§å†…å®¹
                # åˆ é™¤è¡Œå†…çš„ä¸å¯è§å­—ç¬¦ï¼Œä½†ä¿ç•™ç©ºæ ¼ç»“æ„
                cleaned_line = re.sub(r'[\u034f\u00ad\u200b\u200c\u200d\u2060\u0000-\u001f\u007f-\u009f]', '', line)
                processed_lines.append(cleaned_line)
        
        return '\n'.join(processed_lines)

    
    def remove_empty_markdown_links(self, markdown):
        """ä¸“é—¨ç§»é™¤Markdownä¸­çš„ç©ºæ–‡æœ¬é“¾æ¥"""
        if not markdown:
            return ""
        
        # æ¨¡å¼1: å®Œå…¨ç©ºçš„é“¾æ¥æ–‡æœ¬ []()
        markdown = re.sub(r'\[\s*\]\s*\([^)]*\)', '', markdown)
        
        # æ¨¡å¼2: åªæœ‰ç©ºç™½å­—ç¬¦çš„é“¾æ¥æ–‡æœ¬ [   ]()
        markdown = re.sub(r'\[\s+\]\s*\([^)]*\)', '', markdown)
        
        # æ¨¡å¼3: é“¾æ¥æ–‡æœ¬å¾ˆçŸ­ä¸”æ— æ„ä¹‰ï¼ˆå¦‚å•ä¸ªç‚¹ã€ç©ºæ ¼ç­‰ï¼‰
        # åŒ¹é… [.]()ã€[-]() ç­‰æ— æ„ä¹‰çŸ­æ–‡æœ¬
        markdown = re.sub(r'\[([.\-\s]{1,2})\]\s*\([^)]*\)', '', markdown)
        
        # æ¨¡å¼4: é“¾æ¥æ–‡æœ¬ä¸URLç›¸åŒä½†æ˜¾ç¤ºä¸ºç©ºçš„æƒ…å†µ
        # è¿™ç§æƒ…å†µéœ€è¦æ›´å¤æ‚çš„å¤„ç†
        lines = markdown.split('\n')
        processed_lines = []
        
        for line in lines:
            # æŸ¥æ‰¾æ‰€æœ‰é“¾æ¥æ¨¡å¼
            links = re.findall(r'\[([^\]]*)\]\(([^)]*)\)', line)
            for link_text, link_url in links:
                # å¦‚æœé“¾æ¥æ–‡æœ¬ä¸ºç©ºæˆ–åªæœ‰ç©ºç™½ï¼Œç§»é™¤æ•´ä¸ªé“¾æ¥
                if not link_text.strip():
                    line = line.replace(f'[{link_text}]({link_url})', '')
                # å¦‚æœé“¾æ¥æ–‡æœ¬å¾ˆçŸ­ä¸”å¯èƒ½æ˜¯æ— æ„ä¹‰çš„
                elif len(link_text.strip()) <= 2 and link_text.strip() in ['.', '-', 'Â·', 'â€¢']:
                    line = line.replace(f'[{link_text}]({link_url})', '')
            
            processed_lines.append(line)
        
        return '\n'.join(processed_lines)
   
    def normalize_essential_symbols(self, text):
        """åªå¤„ç†MarkdownV2å¿…é¡»å¤„ç†çš„ç¬¦å·"""
        translation_map = str.maketrans({
            # å¿…é¡»å¤„ç†çš„ï¼ˆå½±å“Markdownè¯­æ³•ï¼‰
            'ï¼ˆ': '(',  # æ‹¬å·
            'ï¼‰': ')',
            'ã€': '[',
            'ã€‘': ']',
            'ï¼ƒ': '#',  # äº•å·
            
            # å»ºè®®å¤„ç†çš„
            'ï¼š': ':',  # å†’å·
            'ï¼': '!',  # æ„Ÿå¹å·
        })
        
        text = text.translate(translation_map)
        
        # é¢å¤–çš„æ­£åˆ™å¤„ç†
        import re
        # å¤„ç† ] å’Œ ( ä¹‹é—´çš„ç©ºæ ¼
        text = re.sub(r'\]\s*\(', '](', text)
        # å¤„ç† [ å’Œ ] ä¹‹é—´çš„ç©ºæ ¼
        text = re.sub(r'\[\s*', '[', text)
        text = re.sub(r'\s*\]', ']', text)
        
        return text
    
    def escape_markdown_v2(self, text):
        """ä½¿ç”¨md2tgmdè¿›è¡ŒMarkdownV2æ ¼å¼è½¬ä¹‰ï¼Œç„¶åæ¸…ç†ç­‰ä½“å­—ä¸­çš„åæ–œæ å¹¶ä¿®å¤ç­‰ä½“å­—å†…çš„URL"""
        if not text:
            return ""
        
        print(f"ğŸ”¤ åŸå§‹æ–‡æœ¬: {text}")
        
        # ç¬¬ä¸€æ­¥ï¼šå®‰å…¨æ›¿æ¢ç‚¹å·ï¼ˆåœ¨ç¿»è¯‘åå¤„ç†ï¼‰
        text = self.replace_dots_safely(text)
   #     print(f"ğŸ”¤ æ›¿æ¢ç‚¹å·å: {text}")
        
        # æ–°å¢ï¼šåœ¨è½¬ä¹‰ä¹‹å‰æ¸…ç†ç¬¦å·
        text = re.sub(r'#+', '# ', text)
        text = re.sub(r'\u200c+', '\u200c', text)
        
        text = self.normalize_essential_symbols(text)

        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨md2tgmdè¿›è¡Œè½¬ä¹‰
        escaped_text = escape(text)
        print(f"ğŸ”„ è½¬ä¹‰åæ–‡æœ¬: {escaped_text}")
        
        # ç¬¬ä¸‰æ­¥ï¼šåœ¨è½¬ä¹‰ä¹‹åï¼Œç­‰ä½“å­—å¤„ç†ä¹‹å‰ï¼Œæ£€æŸ¥å‰3è¡Œå¹¶æ›¿æ¢ \_ ä¸º _
        def replace_underscore_escape_in_first_lines(text):
            r"""æ›¿æ¢å‰4è¡Œä¸­çš„ \_ ä¸º _"""
            lines = text.split('\n')
            if len(lines) <= 3:
                return text
                
            processed_lines = []
            for i, line in enumerate(lines):
                if i < 4:  # åªå¤„ç†å‰4è¡Œ
                    # å°† \_ æ›¿æ¢ä¸º _
                    processed_line = line.replace('\\_', '_')
                    if processed_line != line:
                        print(f"ğŸ“ ç¬¬{i+1}è¡Œæ›¿æ¢ \\_ ä¸º _: '{line}' â†’ '{processed_line}'")
                    processed_lines.append(processed_line)
                else:
                    processed_lines.append(line)
            return '\n'.join(processed_lines)
        
        # æ‰§è¡Œå‰3è¡Œ \_ æ›¿æ¢
        escaped_text = replace_underscore_escape_in_first_lines(escaped_text)
        
        # ç¬¬å››æ­¥ï¼šä¸“é—¨å¤„ç†ç­‰ä½“å­—ï¼šæ¸…ç†åæ–œæ  + ä¿®å¤URL
        processed_text = self.clean_and_fix_monospace_urls(escaped_text)
        print(f"ğŸ”— å¤„ç†ç­‰ä½“å­—å: {processed_text}")
        
        # ç¬¬äº”æ­¥ï¼šä¿®å¤ï¼šä¿æŠ¤ä¸»é¢˜ç›¸å…³çš„ä¸‹åˆ’çº¿ï¼ˆåŒ…æ‹¬æ•´ä¸ªä¸»é¢˜ï¼‰
        final_text = self.protect_theme_underscores_complete(processed_text)
        print(f"ğŸ¨ ä¿æŠ¤ä¸»é¢˜ä¸‹åˆ’çº¿å: {final_text}")
        
        return final_text

    def protect_theme_underscores_complete(self, text):
        """
        å®Œæ•´ä¿æŠ¤ä¸»é¢˜ä¸‹åˆ’çº¿ - æ¸…ç†æ•´ä¸ªä¸»é¢˜ä¸¤ç«¯çš„è½¬ä¹‰æ–œæ 
        """
        if not text:
            return text
        
        result = text
        
        # 1. é¦–å…ˆå¤„ç†æ•´ä¸ªä¸»é¢˜çš„æ–œä½“æ ¼å¼
        # åŒ¹é…æ¨¡å¼ï¼šä¸»é¢˜å‰åçš„ \_...\_
        # ä¾‹å¦‚ï¼š\_\[GitHub\] penggan 00/CF-Workers-Buttonsä¸­çš„"ä¸Šæ¸¸åŒæ­¥"å·¥ä½œæµå·²è¢«ç¦ç”¨\_
        theme_pattern = r'\\_([^_]+)\\_'
        
        def restore_theme_handler(match):
            content = match.group(1)
            print(f"ğŸ›¡ï¸ ä¿®å¤ä¸»é¢˜æ–œä½“: '{content}'")
            return f"_{content}_"
        
        # åº”ç”¨ä¸»é¢˜ä¿®å¤
        result = re.sub(theme_pattern, restore_theme_handler, result)
        
        # 2. å¤„ç†ç‰¹å®šæ ¼å¼çš„ä¸»é¢˜ï¼šä¸»é¢˜ï¼š\_å†…å®¹\_
        specific_pattern = r'ä¸»é¢˜[ï¼š:]\s*\\_([^_]+)\\_'
        
        def restore_specific_handler(match):
            content = match.group(1)
            return f"ä¸»é¢˜ï¼š_{content}_"
        
        result = re.sub(specific_pattern, restore_specific_handler, result)
        
        # 3. å¤„ç†è¢«é”™è¯¯è½¬ä¹‰çš„å…¶ä»–æ–œä½“å†…å®¹
        # åŒ¹é…å•ç‹¬çš„ \_ è½¬ä¹‰ï¼ˆä¸åœ¨ç­‰ä½“å­—å†…ï¼‰
        isolated_underscore_pattern = r'(?<!`)\\_(?!`)'
        result = re.sub(isolated_underscore_pattern, '_', result)
        
        # è°ƒè¯•ä¿¡æ¯
        theme_fixes = len(re.findall(theme_pattern, text))
        specific_fixes = len(re.findall(specific_pattern, text))
        
        if theme_fixes + specific_fixes > 0:
            print(f"ğŸ›¡ï¸ ä¸»é¢˜ä¸‹åˆ’çº¿ä¿æŠ¤: ä¿®å¤äº† {theme_fixes} ä¸ªå®Œæ•´ä¸»é¢˜å’Œ {specific_fixes} ä¸ªç‰¹å®šæ ¼å¼")
        
        return result
    
    def clean_and_fix_monospace_urls(self, text):
        """ä¸“é—¨å¤„ç†ç­‰ä½“å­—ï¼šå®‰å…¨æ¸…ç†åæ–œæ  + ä¿®å¤URL - åªåœ¨ç­‰ä½“å­—å†…æ“ä½œ"""
        print(f"ğŸ” å¼€å§‹å¤„ç†ç­‰ä½“å­—ï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}")
        
        def process_monospace_content(match):
            content = match.group(1)
            print(f"\nğŸ” æ‰¾åˆ°ç­‰ä½“å­—å†…å®¹: '{content}' (é•¿åº¦: {len(content)})")
            
            # ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½æ¸…ç†åæ–œæ 
            if self.looks_like_url(content):
                # URLç‰¹æ®Šå¤„ç†ï¼šä¿æŠ¤URLç»“æ„
                cleaned_content = self.clean_url_backslashes_safe(content)
                print(f"ğŸ”— ç­‰ä½“å­—å†…URLåæ–œæ æ¸…ç†: '{content}' â†’ '{cleaned_content}'")
            else:
                # éURLå†…å®¹ï¼šå®‰å…¨æ¸…ç†ï¼Œåªç§»é™¤Markdownè½¬ä¹‰å­—ç¬¦å‰çš„åæ–œæ 
                cleaned_content = self.safe_remove_markdown_backslashes(content)
                if cleaned_content != content:
                    print(f"ğŸ“ ç­‰ä½“å­—å†…éURLåæ–œæ æ¸…ç†: '{content}' â†’ '{cleaned_content}'")
            
            # ç¬¬äºŒæ­¥ï¼šå¦‚æœæ˜¯URLåˆ™ä¿®å¤æ ¼å¼
            if self.looks_like_url(cleaned_content):
             #   print(f"ğŸŒ ç­‰ä½“å­—å†…æ£€æµ‹åˆ°URLï¼Œå¼€å§‹ä¿®å¤: '{cleaned_content}'")
                fixed_content = self.fix_translated_url_specific(cleaned_content)
            #    print(f"âœ… ç­‰ä½“å­—å†…URLä¿®å¤ç»“æœ: '{cleaned_content}' â†’ '{fixed_content}'")
                return f'`{fixed_content}`'
            else:
            #    print(f"âŒ ç­‰ä½“å­—å†…ä¸æ˜¯URLï¼Œè·³è¿‡ä¿®å¤: '{cleaned_content}'")
                return f'`{cleaned_content}`'
        
        # åªå¤„ç†ç­‰ä½“å­—å†…çš„å†…å®¹ï¼Œä½¿ç”¨æ­£åˆ™åŒ¹é… `å†…å®¹`
        result = re.sub(r'`([^`]*)`', process_monospace_content, text)
        print(f"\nğŸ“ ç­‰ä½“å­—å¤„ç†å®Œæˆ")
        return result

    def clean_url_backslashes_safe(self, url_content):
        """å®‰å…¨æ¸…ç†URLä¸­çš„åæ–œæ ï¼Œä¿æŠ¤URLç»“æ„"""
        if not url_content:
            return url_content
        
        original = url_content
        
        try:
            # é€æ­¥æ¸…ç†ï¼Œä¿æŠ¤URLå…³é”®éƒ¨åˆ†
            steps = [
                # 1. ä¿®å¤åè®®éƒ¨åˆ†ï¼šhttps:\/\/ â†’ https://
                (r'https?\\\\?/\\\\?/', lambda m: m.group(0).replace('\\', '')),
                # 2. ä¿®å¤è·¯å¾„åˆ†éš”ç¬¦ï¼špath\/to â†’ path/to
                (r'([^/])\\\\?/', r'\1/'),
                # 3. ä¿®å¤æŸ¥è¯¢å‚æ•°åˆ†éš”ç¬¦ï¼š?\&aff= â†’ ?&aff=
                (r'([?&])\\\\?', r'\1'),
                # 4. ä¿®å¤ç­‰å·ï¼šaff\=123 â†’ aff=123
                (r'\\=', '='),
                # 5. è°¨æ…æ¸…ç†å…¶ä»–åæ–œæ ï¼šåªæ¸…ç†æ˜æ˜¾å¤šä½™çš„åæ–œæ 
                (r'\\([^a-zA-Z0-9])', r'\1'),  # åªæ¸…ç†éå­—æ¯æ•°å­—å‰çš„åæ–œæ 
            ]
            
            result = url_content
            for pattern, replacement in steps:
                result = re.sub(pattern, replacement, result)
            
            # æœ€ç»ˆæ£€æŸ¥ï¼šå¦‚æœè¿˜æœ‰è¿ç»­çš„åæ–œæ ï¼Œä½†URLç»“æ„çœ‹èµ·æ¥æ­£å¸¸ï¼Œå°±ä¿ç•™
            if '\\' in result and self.is_valid_url_structure(result):
                print(f"âš ï¸  URLä¸­ä»æœ‰åæ–œæ ï¼Œä½†ç»“æ„æ­£å¸¸ï¼Œä¿ç•™: '{result}'")
            
            return result
            
        except Exception as e:
            print(f"âŒ URLåæ–œæ æ¸…ç†å‡ºé”™: {e}")
            return original

    def safe_remove_markdown_backslashes(self, text):
        """
        å®‰å…¨åœ°ç§»é™¤Markdownè½¬ä¹‰å­—ç¬¦å‰çš„åæ–œæ 
        åªç§»é™¤Telegram MarkdownV2ç‰¹æ®Šå­—ç¬¦å‰çš„åæ–œæ 
        """
        if not text:
            return text
        
        # Telegram MarkdownV2éœ€è¦è½¬ä¹‰çš„ç‰¹æ®Šå­—ç¬¦
        markdown_special_chars = '_*[]()~`>#+-=|{}.!'
        
        result = text
        for char in markdown_special_chars:
            # åªç§»é™¤ç‰¹æ®Šå­—ç¬¦å‰çš„åæ–œæ ï¼Œä¿ç•™å…¶ä»–åæ–œæ 
            pattern = re.escape('\\' + char)
            result = re.sub(pattern, char, result)
        
        return result

    def is_valid_url_structure(self, text):
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦å…·æœ‰æœ‰æ•ˆçš„URLç»“æ„"""
        url_indicators = [
            r'https?://',
            r'www\.',
            r'\.(com|org|net|io|cn)',
            r'/\w',
            r'\?',
            r'=',
        ]
        
        return any(re.search(pattern, text, re.IGNORECASE) for pattern in url_indicators)

    def fix_translated_url_specific(self, url_content):
        """ä¸“é—¨ä¿®å¤ç­‰ä½“å­—å†…è¢«ç¿»è¯‘ç ´åçš„URLå†…å®¹"""
        if not url_content:
            return url_content
        
        original_content = url_content
        print(f"ğŸ› ï¸ å¼€å§‹ä¿®å¤ç­‰ä½“å­—å†…URL: '{original_content}'")
        
        # è®°å½•æ¯ä¸€æ­¥çš„å˜åŒ–
        steps = []
        
        # 1. ä¿®å¤ä¸­æ–‡å†’å·
        before_colon = url_content
        url_content = url_content.replace('ï¼š', ':')
        if url_content != before_colon:
            steps.append(f"ä¸­æ–‡å†’å·ä¿®å¤: '{before_colon}' â†’ '{url_content}'")
        
        # 2. ä¿®å¤åè®®éƒ¨åˆ† - å¢å¼ºå¤„ç†
        before_protocol = url_content
        url_content = re.sub(r'https?[\sï¼š:]*//', 'https://', url_content)
        url_content = re.sub(r'http[\sï¼š:]*//', 'http://', url_content)
        
        # 3. å¤„ç†ç¼ºå°‘åè®®çš„æƒ…å†µ
        before_protocol_add = url_content
        if not url_content.startswith(('http://', 'https://')):
            # å¦‚æœæ˜¯ racknerd åŸŸåï¼Œæ·»åŠ  https://
            if url_content.startswith('my.racknerd'):
                url_content = 'https://' + url_content
                steps.append(f"æ·»åŠ åè®®: '{before_protocol_add}' â†’ '{url_content}'")
            # å¤„ç† https:example.com è¿™ç§æƒ…å†µ
            elif re.match(r'https?:[^/]', url_content):
                url_content = url_content.replace(':', '://', 1)
                steps.append(f"æ·»åŠ //: '{before_protocol_add}' â†’ '{url_content}'")
            # å¤„ç†ç›´æ¥åŸŸåçš„æƒ…å†µ
            elif re.match(r'[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', url_content):
                url_content = 'https://' + url_content
                steps.append(f"æ·»åŠ httpsåè®®: '{before_protocol_add}' â†’ '{url_content}'")
        
        # 4. å½»åº•åˆ é™¤æ‰€æœ‰ç©ºæ ¼
        before_spaces = url_content
        url_content = re.sub(r'\s+', '', url_content)
        if url_content != before_spaces:
            steps.append(f"åˆ é™¤ç©ºæ ¼: '{before_spaces}' â†’ '{url_content}'")
        
        # 5. ä¸“é—¨ä¿®å¤racknerdå‚æ•°æ ¼å¼ - å¢å¼ºå¤„ç†
        if 'racknerd' in url_content.lower():
            before_aff = url_content
            
            # ä¿®å¤ aff 14818 â†’ aff=14818 (å¤šç§æ ¼å¼)
            url_content = re.sub(r'aff\s*=\s*(\d+)', r'aff=\1', url_content, flags=re.IGNORECASE)
            url_content = re.sub(r'aff\s*(\d+)', r'aff=\1', url_content, flags=re.IGNORECASE)
            url_content = re.sub(r'\.php\?\s*', '.php?', url_content)
            
            # ç¡®ä¿å®Œæ•´çš„URLæ ¼å¼
            if 'aff.php?' in url_content and 'aff=' not in url_content:
                url_content = re.sub(r'aff\.php\?(\d+)', r'aff.php?aff=\1', url_content)
            
            if url_content != before_aff:
                steps.append(f"affå‚æ•°ä¿®å¤: '{before_aff}' â†’ '{url_content}'")
        
        # 6. æœ€ç»ˆéªŒè¯å’Œæ¸…ç†
        before_final = url_content
        # ç¡®ä¿URLä»¥åè®®å¼€å¤´
        if not url_content.startswith(('http://', 'https://')) and '://' not in url_content:
            if 'racknerd' in url_content.lower():
                url_content = 'https://' + url_content.lstrip('/')
                steps.append(f"æœ€ç»ˆåè®®ä¿®å¤: '{before_final}' â†’ '{url_content}'")
        
        # è¾“å‡ºä¿®å¤æ­¥éª¤
        if steps:
            print(f"ğŸ“‹ ç­‰ä½“å­—å†…URLä¿®å¤æ­¥éª¤:")
            for step in steps:
                print(f"   {step}")
        else:
            print(f"â„¹ï¸ ç­‰ä½“å­—å†…URLæ— éœ€ä¿®å¤")
        
        print(f"ğŸ‰ ç­‰ä½“å­—å†…URLä¿®å¤å®Œæˆ: '{original_content}' â†’ '{url_content}'")
        
        return url_content

    def looks_like_url(self, text):
        """å¢å¼ºçš„URLæ£€æµ‹ï¼Œå¤„ç†å„ç§è¢«ç ´åçš„URLæ ¼å¼"""
        if not text:
            return False
        
        # æ¸…ç†æ–‡æœ¬ä»¥ä¾¿æ£€æµ‹
        cleaned = text.replace('ï¼š', ':').replace(' ', '')
        
        # æ‰©å±•URLç‰¹å¾æ¨¡å¼ - æ›´å®½æ¾çš„æ£€æµ‹
        url_indicators = [
            r'https?[:ï¼š]',              # åŒ…å« http: æˆ– https:
            r'https?[:ï¼š][^/]',          # åŒ…å« http:example.com (ç¼ºå°‘//)
            r'my\.racknerd',             # åŒ…å« racknerd åŸŸå
            r'racknerd.*aff',            # racknerdç›¸å…³affé“¾æ¥
            r'\.php\?',                  # PHPå‚æ•°
            r'aff\.php',                 # aff.phpæ–‡ä»¶
            r'aff.*\d+',                 # affåŠ æ•°å­—
            r'^[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}',  # åŸŸåæ¨¡å¼
        ]
        
        for pattern in url_indicators:
            if re.search(pattern, cleaned, re.IGNORECASE):
                print(f"ğŸ”— è¯†åˆ«ä¸ºURL: '{text}' â†’ åŒ¹é…æ¨¡å¼: {pattern}")
                return True
        
        print(f"ğŸš« ä¸æ˜¯URL: '{text}'")
        return False
    
    def split_message(self, text, max_length=3800):
        """åˆ†å‰²é•¿æ¶ˆæ¯ä»¥é€‚åº”Telegramé™åˆ¶ï¼ˆè€ƒè™‘è½¬ä¹‰åçš„é•¿åº¦ï¼‰"""
        if len(text) <= max_length:
            return [text]
        
        parts = []
        while text:
            if len(text) <= max_length:
                parts.append(text)
                break
            
            # åœ¨æœ€å¤§é•¿åº¦é™„è¿‘æ‰¾æ¢è¡Œç¬¦åˆ†å‰²
            split_pos = text.rfind('\n', 0, max_length)
            if split_pos == -1:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ¢è¡Œç¬¦ï¼Œå°±åœ¨å•è¯è¾¹ç•Œåˆ†å‰²
                split_pos = text.rfind(' ', 0, max_length)
                if split_pos == -1:
                    split_pos = max_length
            
            parts.append(text[:split_pos])
            text = text[split_pos:].lstrip()
            
            # æ·»åŠ ç»­æ¥æ ‡è¯†
            if text:
                parts[-1] += "\n\nã€æ¶ˆæ¯ç»­æ¥...ã€‘"
                text = "ã€æ¥ä¸Šæ¡æ¶ˆæ¯ã€‘\n" + text
            
        return parts
    
    async def send_to_telegram_async(self, markdown_content, chat_id):
        """ä½¿ç”¨python-telegram-botå‘é€Markdownå†…å®¹"""
        
        # è½¬ä¹‰Markdownå†…å®¹
        escaped_content = self.escape_markdown_v2(markdown_content)
        escaped_content = re.sub(r'(\n\s*){3,}', '\n\n', escaped_content)
        escaped_content = re.sub(r'^\n+', '', escaped_content)
        escaped_content = re.sub(r'\n+$', '', escaped_content)

        # åœ¨å‘é€å‰æ‰“å°åˆ°ç»ˆç«¯
        print("\n" + "="*80)
        print("ğŸ“¤ å‡†å¤‡å‘é€åˆ° Telegram çš„æ¶ˆæ¯å†…å®¹:")
        print("="*80)
        print(markdown_content)
        print("="*80)
        print("ğŸ”¤ è½¬ä¹‰åçš„æ¶ˆæ¯å†…å®¹:")
        print("="*80)
        print(escaped_content)
        print("="*80)
        print(f"ğŸ’¬ ç›®æ ‡èŠå¤©ID: {chat_id}")
        print("="*80 + "\n")

        try:
            # é¦–å…ˆå°è¯•å‘é€MarkdownV2æ ¼å¼
            await self.bot.send_message(
                chat_id=chat_id,
                text=escaped_content,
                parse_mode=ParseMode.MARKDOWN_V2,
                disable_web_page_preview=True
            )
      #      logging.info(f"æ¶ˆæ¯æˆåŠŸå‘é€åˆ°èŠå¤© {chat_id} (MarkdownV2æ ¼å¼)")
            return True
            
        except Exception as e:
            logging.warning(f"MarkdownV2å‘é€å¤±è´¥ï¼Œå°è¯•çº¯æ–‡æœ¬æ ¼å¼: {e}")
            
            # Markdownå‘é€å¤±è´¥ï¼Œé™çº§åˆ°çº¯æ–‡æœ¬
            return await self._send_as_plaintext_async(markdown_content, chat_id)

    async def _send_as_plaintext_async(self, original_content, chat_id):
        """ä»¥çº¯æ–‡æœ¬æ ¼å¼å‘é€æ¶ˆæ¯"""
        try:
            # æ¸…ç†å†…å®¹ï¼Œç§»é™¤Markdownç‰¹æ®Šå­—ç¬¦ä½†ä¿ç•™åŸºæœ¬æ ¼å¼
            plain_text = self._convert_to_plaintext(original_content)
            
            await self.bot.send_message(
                chat_id=chat_id,
                text=plain_text,
                parse_mode=None,  # ä¸ä½¿ç”¨Markdown
                disable_web_page_preview=True
            )
          #  logging.info(f"æ¶ˆæ¯æˆåŠŸå‘é€åˆ°èŠå¤© {chat_id} (çº¯æ–‡æœ¬æ ¼å¼)")
            return True
            
        except Exception as e:
            logging.error(f"çº¯æ–‡æœ¬å‘é€ä¹Ÿå¤±è´¥: {e}")
            return False

    def _convert_to_plaintext(self, markdown_content):
        """å°†Markdownå†…å®¹è½¬æ¢ä¸ºå®‰å…¨çš„çº¯æ–‡æœ¬"""
        if not markdown_content:
            return ""
        
        text = markdown_content
        
        # åˆ†æ­¥éª¤æ¸…ç†Markdownè¯­æ³•
        # 1. ç§»é™¤ä»£ç å—
        text = re.sub(r'```.*?\n(.*?)\n```', r'\1', text, flags=re.DOTALL)
        
        # 2. ç§»é™¤è¡Œå†…ä»£ç 
        text = re.sub(r'`(.*?)`', r'\1', text)
        
        # 3. ç§»é™¤ç²—ä½“å’Œæ–œä½“æ ‡è®°ä½†ä¿ç•™å†…å®¹
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # ç²—ä½“
        text = re.sub(r'\*(.*?)\*', r'\1', text)      # æ–œä½“
        text = re.sub(r'__(.*?)__', r'\1', text)      # ä¸‹åˆ’çº¿ç²—ä½“
        text = re.sub(r'_(.*?)_', r'\1', text)        # ä¸‹åˆ’çº¿æ–œä½“
        
        # 4. ç§»é™¤é“¾æ¥æ ‡è®°ä½†ä¿ç•™æ–‡æœ¬
     #   text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)  # [æ–‡æœ¬](é“¾æ¥) -> æ–‡æœ¬
        
        # 5. ç§»é™¤å¯èƒ½å¼•èµ·é—®é¢˜çš„ç‰¹æ®Šå­—ç¬¦ï¼ˆä½†ä¿ç•™åŸºæœ¬æ ‡ç‚¹ï¼‰
      #  problematic_chars = r'[\\`*_{}[\]()#+-.!|~>]'
        problematic_chars = r'[\\#]'  # åªåŒ¹é…åæ–œæ å’Œäº•å·
        text = re.sub(problematic_chars, ' ', text)
        
        # 6. æ ‡å‡†åŒ–ç©ºç™½ï¼ˆä¿ç•™æ®µè½ç»“æ„ï¼‰
       # text = re.sub(r'[ \t]+', ' ', text)  # åˆå¹¶å¤šä¸ªç©ºæ ¼
        text = re.sub(r'\n[ \t]*\n[ \t]*\n+', '\n\n', text)  # ä¿ç•™æœ€å¤šä¸¤ä¸ªè¿ç»­ç©ºè¡Œ
        text = re.sub(r'^\n+', '', text)  # ç§»é™¤å¼€å¤´çš„ç©ºè¡Œ
        text = re.sub(r'\n+$', '', text)  # ç§»é™¤ç»“å°¾çš„ç©ºè¡Œ
        
        return text.strip()
    
    async def send_to_all_chats_async(self, markdown_content):
        """å°†æ¶ˆæ¯å‘é€åˆ°å•ä¸ªé…ç½®çš„èŠå¤©"""
        message_parts = self.split_message(markdown_content)
        
        # æ‰“å°åˆ†æ®µä¿¡æ¯
        print(f"\nğŸ“¦ æ¶ˆæ¯è¢«åˆ†å‰²æˆ {len(message_parts)} éƒ¨åˆ†")
        for i, part in enumerate(message_parts, 1):
            print(f"ğŸ“„ ç¬¬ {i}/{len(message_parts)} éƒ¨åˆ† (é•¿åº¦: {len(part)} å­—ç¬¦):")
            print("-" * 40)
            print(part[:200] + "..." if len(part) > 200 else part)
            print("-" * 40)
        
        # åªå‘é€åˆ°ç¬¬ä¸€ä¸ªèŠå¤©ID
        if not self.telegram_config['chat_ids']:
            logging.error("æ²¡æœ‰é…ç½®èŠå¤©ID")
            return False
        
        chat_id = self.telegram_config['chat_ids'][0]
        chat_success = True
        
        for i, part in enumerate(message_parts):
      #      print(f"\nğŸš€ æ­£åœ¨å‘é€åˆ°èŠå¤© {chat_id} - ç¬¬ {i+1}/{len(message_parts)} éƒ¨åˆ†")
            success = await self.send_to_telegram_async(part, chat_id)
            if not success:
                chat_success = False
                logging.error(f"èŠå¤© {chat_id} çš„ç¬¬ {i+1} éƒ¨åˆ†å‘é€å¤±è´¥")
                break
            
            # çŸ­æš‚å»¶è¿Ÿé¿å…é€Ÿç‡é™åˆ¶
            if i < len(message_parts) - 1:
                await asyncio.sleep(1)
        
        if chat_success:
            pass
        else:
            logging.error(f"æ¶ˆæ¯å‘é€åˆ°èŠå¤© {chat_id} å¤±è´¥")
        
        return chat_success

    async def process_single_email_async(self, mail, email_id):
        """å¼‚æ­¥å¤„ç†å•å°é‚®ä»¶"""
        try:
            # è·å–é‚®ä»¶æ•°æ®
            status, msg_data = mail.fetch(email_id, '(RFC822)')
            if status != 'OK':
                logging.warning(f"è·å–é‚®ä»¶ {email_id} å†…å®¹å¤±è´¥")
                return False
            
            # è§£æé‚®ä»¶
            msg = email.message_from_bytes(msg_data[0][1])
            email_data = self.extract_email_content(msg)
            
          #  print(f"\nğŸ“§ å¤„ç†é‚®ä»¶:")
         #   print(f"   ä¸»é¢˜: {email_data['subject']}")
         #   print(f"   å‘ä»¶äºº: {email_data['from']}")
         #   print(f"   æ—¥æœŸ: {email_data['date']}")
            
       #     logging.info(f"å¤„ç†é‚®ä»¶ - ä¸»é¢˜: {email_data['subject']}, å‘ä»¶äºº: {email_data['from']}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸­å›½é“¶è¡Œä¿¡ç”¨å¡é‚®ä»¶
            if self.is_boc_credit_card_email(email_data):
             #   print(f"\nğŸ¦ æ£€æµ‹åˆ°ä¸­å›½é“¶è¡Œä¿¡ç”¨å¡é‚®ä»¶ï¼Œå¼€å§‹å¤„ç†PDFé™„ä»¶")
                pdf_content = self.extract_and_parse_pdf_attachments(msg)
                
                if pdf_content:
                #    print(f"âœ… æˆåŠŸè§£æPDFé™„ä»¶ï¼Œæœ€ç»ˆå†…å®¹é•¿åº¦: {len(pdf_content)} å­—ç¬¦")
                    markdown_content = self.create_pdf_message(email_data, pdf_content)
                else:
                    print(f"âŒ æœªæ‰¾åˆ°PDFé™„ä»¶æˆ–è§£æå¤±è´¥ï¼Œå‘é€æ™®é€šé‚®ä»¶å†…å®¹")
                    markdown_content = self.convert_email_to_markdown(email_data)
                    markdown_content = "ğŸ¦ ä¸­å›½é“¶è¡Œä¿¡ç”¨å¡é‚®ä»¶ï¼ˆæ— PDFé™„ä»¶ï¼‰\n\n" + markdown_content
                
                success = await self.send_to_all_chats_async(markdown_content)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å»ºè®¾é“¶è¡Œä¿¡ç”¨å¡é‚®ä»¶
            elif self.is_ccb_credit_card_email(email_data):
             #   print(f"\nğŸ¦ æ£€æµ‹åˆ°å»ºè®¾é“¶è¡Œä¿¡ç”¨å¡é‚®ä»¶ï¼Œå¼€å§‹å¤„ç†HTMLå†…å®¹")
                original_markdown = self.convert_email_to_markdown(email_data)
                markdown_content = self.format_ccb_email_content(email_data, original_markdown)
                
            #    print(f"\nğŸ“¤ å‡†å¤‡å‘é€çš„å®Œæ•´æ¶ˆæ¯:")
                print("="*80)
                print(markdown_content)
                print("="*80)
                
                success = await self.send_to_all_chats_async(markdown_content)
            
            else:
                # æ­£å¸¸å¤„ç†å…¶ä»–é‚®ä»¶
                print(f"ğŸ“§ æ™®é€šé‚®ä»¶ï¼Œæ­£å¸¸å¤„ç†")
                markdown_content = self.convert_email_to_markdown(email_data)
                success = await self.send_to_all_chats_async(markdown_content)
            
            if success:
                # æ ‡è®°ä¸ºå·²è¯»
                mail.store(email_id, '+FLAGS', '\\Seen')
                print(f"âœ… é‚®ä»¶ {email_id} å¤„ç†å®Œæˆå¹¶æ ‡è®°ä¸ºå·²è¯»")
            else:
                print(f"âŒ é‚®ä»¶ {email_id} å‘é€åˆ°éƒ¨åˆ†TelegramèŠå¤©å¤±è´¥")
            
            return success
            
        except Exception as e:
            print(f"âŒ å¤„ç†é‚®ä»¶ {email_id} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            logging.error(f"å¤„ç†é‚®ä»¶ {email_id} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def format_boc_statement(self, pdf_content):
        """æ ¼å¼åŒ–ä¸­å›½é“¶è¡Œä¿¡ç”¨å¡è´¦å•å†…å®¹ - ä¿®å¤äº¤æ˜“æ˜ç»†æ˜¾ç¤º"""
        try:
            print(f"\nğŸ’° å¼€å§‹æ ¼å¼åŒ–è´¦å•å†…å®¹")
            print(f"   åŸå§‹PDFå†…å®¹é•¿åº¦: {len(pdf_content)} å­—ç¬¦")
            
            # æå–å…³é”®ä¿¡æ¯
            account_info = self.extract_account_info(pdf_content)
            transaction_details = self.extract_transaction_details(pdf_content)
            summary_info = self.extract_summary_info(pdf_content)
            
            print(f"   æå–åˆ°è´¦æˆ·ä¿¡æ¯: {len(account_info)} é¡¹")
            print(f"   æå–åˆ°äº¤æ˜“æ˜ç»†: {len(transaction_details)} æ¡")
            print(f"   æå–åˆ°è´¦å•æ¦‚è§ˆ: {len(summary_info)} é¡¹")
            
            formatted_message = ""  
            # è´¦æˆ·åŸºæœ¬ä¿¡æ¯
            formatted_message += "**ğŸ“‹ è´¦æˆ·ä¿¡æ¯**\n"
            formatted_message += f"æŒå¡äºº: {account_info.get('holder_name', 'æœªçŸ¥')}\n"
            formatted_message += f"å¡å·: {account_info.get('card_number', 'æœªçŸ¥')}\n"
            formatted_message += f"è´¦å•å‘¨æœŸ: {account_info.get('billing_period', 'æœªçŸ¥')}\n"
            formatted_message += f"è´¦å•æ—¥: {account_info.get('statement_date', 'æœªçŸ¥')}\n"
            formatted_message += f"åˆ°æœŸè¿˜æ¬¾æ—¥: {account_info.get('due_date', 'æœªçŸ¥')}\n\n"
            
            # è´¦å•æ¦‚è§ˆ
            formatted_message += "**ğŸ’° è´¦å•æ¦‚è§ˆ**\n"
            formatted_message += f"æœ¬æœŸäººæ°‘å¸æ¬ æ¬¾: Â¥{summary_info.get('min_payment', '0.00')}\n"
            formatted_message += f"æœ¬æœŸå¤–å¸æ¬ æ¬¾: ${summary_info.get('foreign_balance', '0.00')}\n"
            formatted_message += f"æœ€ä½è¿˜æ¬¾é¢: Â¥{summary_info.get('rmb_balance', '0.00')}\n"
            formatted_message += f"è´¦å•å¯åˆ†æœŸé‡‘é¢: Â¥{summary_info.get('installment_available', '0.00')}\n\n"
            
            # äº¤æ˜“æ˜ç»† - æ˜¾ç¤ºæ‰€æœ‰è®°å½•
            if transaction_details:
                formatted_message += "**ğŸ’³ äº¤æ˜“æ˜ç»†**\n"
                total_expenditure = 0
                total_deposit = 0
                
                # ç§»é™¤æ•°é‡é™åˆ¶ï¼Œæ˜¾ç¤ºæ‰€æœ‰äº¤æ˜“è®°å½•
                for i, transaction in enumerate(transaction_details, 1):
                    date = transaction.get('date', 'æœªçŸ¥æ—¥æœŸ')
                    description = transaction.get('description', '')
                    amount = transaction.get('amount', '0.00')
                    tx_type = transaction.get('type', 'æ”¯å‡º')
                    
                    # è®¡ç®—æ€»æ”¯å‡ºå’Œæ€»å­˜å…¥
                    if tx_type == "æ”¯å‡º":
                        total_expenditure += float(amount)
                        # æ”¯å‡ºç”¨ - å·
                        formatted_message += f"{i}. `{date}` {description} "
                        formatted_message += f" Â¥:-{amount}\n"
                    else:
                        total_deposit += float(amount)
                        # å­˜å…¥ç”¨ + å·
                        formatted_message += f"{i}. `{date}` {description} "
                        formatted_message += f" Â¥:+{amount}\n"
                
                # æ˜¾ç¤ºäº¤æ˜“ç»Ÿè®¡
                formatted_message += f"\n**ğŸ“Š äº¤æ˜“ç»Ÿè®¡**\n"
                formatted_message += f"æœ¬æœˆæ€»æ”¯å‡º: Â¥{total_expenditure:.2f}\n"
                formatted_message += f"æœ¬æœˆæ€»å­˜å…¥: Â¥{total_deposit:.2f}\n"
                formatted_message += f"äº¤æ˜“ç¬”æ•°: {len(transaction_details)} ç¬”\n"
                formatted_message += f"å‡€æ”¯å‡º: Â¥{total_expenditure - total_deposit:.2f}\n"
            else:
                formatted_message += "**ğŸ’³ äº¤æ˜“æ˜ç»†**\n"
                formatted_message += "æ— äº¤æ˜“è®°å½•\n"
            
            # è¿˜æ¬¾æé†’
            formatted_message += "\n**â° è¿˜æ¬¾æé†’**\n"
            formatted_message += f"è¯·äº {account_info.get('due_date', 'åˆ°æœŸæ—¥')} å‰è¿˜æ¬¾\n"
            formatted_message += f"å…¨é¢è¿˜æ¬¾: Â¥{summary_info.get('min_payment', '0.00')}\n"
            formatted_message += f"æœ€ä½è¿˜æ¬¾: Â¥{summary_info.get('rmb_balance', '0.00')}\n"
            
            print(f"âœ… è´¦å•æ ¼å¼åŒ–å®Œæˆï¼Œæœ€ç»ˆæ¶ˆæ¯é•¿åº¦: {len(formatted_message)} å­—ç¬¦")
            
            return formatted_message
            
        except Exception as e:
            print(f"âŒ æ ¼å¼åŒ–è´¦å•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return "**ğŸ“„ è´¦å•å†…å®¹:**\n" + pdf_content
        
    def extract_transaction_details_from_table(self, table_data):
        """ä»è¡¨æ ¼æ•°æ®ä¸­æå–äº¤æ˜“æ˜ç»†"""
        transactions = []
        
        try:
            print(f"\nğŸ” ä»è¡¨æ ¼æ•°æ®æå–äº¤æ˜“æ˜ç»†...")
            
            # å‡è®¾table_dataæ˜¯äºŒç»´æ•°ç»„
            for row_num, row in enumerate(table_data):
                if len(row) >= 6:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„åˆ—
                    date = row[0] if row[0] else None
                    description = row[3] if len(row) > 3 else ""
                    deposit = row[4] if len(row) > 4 else ""  # å­˜å…¥åˆ—
                    expenditure = row[5] if len(row) > 5 else ""  # æ”¯å‡ºåˆ—
                    
                    # æ¸…ç†æ•°æ®
                    if date and re.match(r'\d{4}-\d{2}-\d{2}', date):
                        description = re.sub(r'\s+', ' ', description).strip()
                        
                        if deposit and deposit != '0.00':
                            # å­˜å…¥äº¤æ˜“
                            transactions.append({
                                'date': date,
                                'description': description,
                                'amount': deposit,
                                'type': 'å­˜å…¥'
                            })
                            print(f"ğŸ’° è¡¨æ ¼å­˜å…¥: {date} {description} +{deposit}")
                        elif expenditure and expenditure != '0.00':
                            # æ”¯å‡ºäº¤æ˜“
                            transactions.append({
                                'date': date,
                                'description': description,
                                'amount': expenditure,
                                'type': 'æ”¯å‡º'
                            })
                            print(f"ğŸ’¸ è¡¨æ ¼æ”¯å‡º: {date} {description} -{expenditure}")
            
            print(f"âœ… è¡¨æ ¼æå–å®Œæˆ: {len(transactions)} æ¡è®°å½•")
            
        except Exception as e:
            print(f"âŒ è¡¨æ ¼æå–å¤±è´¥: {e}")
        
        return transactions
    
    def extract_account_info(self, pdf_content):
        """æå–è´¦æˆ·åŸºæœ¬ä¿¡æ¯"""
        account_info = {}
        
        try:
            # æå–æŒå¡äººå§“å
            name_match = re.search(r'(\S+)\s+å…ˆç”Ÿ', pdf_content)
            if name_match:
                account_info['holder_name'] = name_match.group(1)
            
            # æå–è´¦å•å‘¨æœŸ
            period_match = re.search(r'ä¿¡ç”¨å¡è´¦å•\((\d{4}å¹´\d{1,2}æœˆ)\)', pdf_content)
            if period_match:
                account_info['billing_period'] = period_match.group(1)
            
            # æå–è´¦å•æ—¥å’Œåˆ°æœŸæ—¥
            date_matches = re.findall(r'(\d{4}-\d{2}-\d{2})', pdf_content)
            if len(date_matches) >= 2:
                account_info['statement_date'] = date_matches[1]  # è´¦å•æ—¥
                account_info['due_date'] = date_matches[0]       # åˆ°æœŸæ—¥
            
            # æå–å¡å·
            card_match = re.search(r'6259\s+0747\s+\*\*\*\*\s+(\d{4})', pdf_content)
            if card_match:
                account_info['card_number'] = f"6259 0747 **** {card_match.group(1)}"
            
        except Exception as e:
            logging.error(f"æå–è´¦æˆ·ä¿¡æ¯å¤±è´¥: {e}")
        
        return account_info

    def extract_summary_info(self, pdf_content):
        """æå–è´¦å•æ¦‚è§ˆä¿¡æ¯"""
        summary_info = {}
        
        try:
            # æå–æœ€ä½è¿˜æ¬¾é¢
            rmb_match = re.search(r'æœ¬æœŸäººæ°‘å¸æ¬ æ¬¾æ€»è®¡.*?(\d+\.\d{2})', pdf_content)
            if rmb_match:
                summary_info['rmb_balance'] = rmb_match.group(1)
            
            # æå–å¤–å¸æ¬ æ¬¾
            foreign_match = re.search(r'æœ¬æœŸå¤–å¸æ¬ æ¬¾æ€»è®¡.*?(\d+\.\d{2})', pdf_content)
            if foreign_match:
                summary_info['foreign_balance'] = foreign_match.group(1)
            
            # æå–äººæ°‘å¸æ¬ æ¬¾
            min_payment_match = re.search(r'äººæ°‘å¸RMB.*?(\d+\.\d{2})', pdf_content)
            if min_payment_match:
                summary_info['min_payment'] = min_payment_match.group(1)
            
            # æå–å¯åˆ†æœŸé‡‘é¢
            installment_match = re.search(r'è´¦å•å¯åˆ†æœŸé‡‘é¢.*?(\d+\.\d{2})', pdf_content)
            if installment_match:
                summary_info['installment_available'] = installment_match.group(1)
            
        except Exception as e:
            logging.error(f"æå–è´¦å•æ¦‚è§ˆå¤±è´¥: {e}")
        
        return summary_info

    def extract_transaction_details(self, pdf_content):
        """æå–äº¤æ˜“æ˜ç»† - ä¿®å¤å­˜å…¥äº¤æ˜“ä¸¢å¤±é—®é¢˜"""
        transactions = []
        
        try:
            print(f"\nğŸ” å¼€å§‹æå–äº¤æ˜“æ˜ç»†...")
            
            # ä»è¡¨æ ¼æ•°æ®ä¸­æå–äº¤æ˜“è®°å½•
            lines = pdf_content.split('\n')
            in_transaction_section = False
            
            for line in lines:
                # æ£€æµ‹äº¤æ˜“æ˜ç»†éƒ¨åˆ†
                if 'äººæ°‘å¸äº¤æ˜“æ˜ç»†' in line or 'äº¤æ˜“æè¿°' in line:
                    in_transaction_section = True
                    print(f"âœ… è¿›å…¥äº¤æ˜“æ˜ç»†éƒ¨åˆ†")
                    continue
                
                if in_transaction_section:
                    # åŒ¹é…äº¤æ˜“è®°å½•è¡Œ (åŒ…å«å­˜å…¥å’Œæ”¯å‡º)
                    # åŒ¹é…æ ¼å¼: æ—¥æœŸ æ—¥æœŸ å¡å· æè¿° å­˜å…¥é‡‘é¢ æ”¯å‡ºé‡‘é¢
                    transaction_match = re.match(r'(\d{4}-\d{2}-\d{2})\s+(\d{4}-\d{2}-\d{2})\s+(\d{4})\s+(.*?)\s+(\d+\.\d{2})?\s*(\d+\.\d{2})?', line)
                    if transaction_match:
                        transaction_date = transaction_match.group(1)
                        description = transaction_match.group(4).strip()
                        deposit_amount = transaction_match.group(5)  # å­˜å…¥é‡‘é¢
                        expenditure_amount = transaction_match.group(6)  # æ”¯å‡ºé‡‘é¢
                        
                        # æ¸…ç†æè¿°æ–‡æœ¬
                        description = re.sub(r'CHN$', '', description).strip()
                        
                        # ç¡®å®šäº¤æ˜“ç±»å‹å’Œé‡‘é¢
                        if deposit_amount and deposit_amount != '0.00':
                            # å­˜å…¥äº¤æ˜“
                            transaction_type = "å­˜å…¥"
                            amount = deposit_amount
                            print(f"ğŸ’° å‘ç°å­˜å…¥äº¤æ˜“: {transaction_date} {description} +{amount}")
                        elif expenditure_amount and expenditure_amount != '0.00':
                            # æ”¯å‡ºäº¤æ˜“
                            transaction_type = "æ”¯å‡º" 
                            amount = expenditure_amount
                            print(f"ğŸ’¸ å‘ç°æ”¯å‡ºäº¤æ˜“: {transaction_date} {description} -{amount}")
                        else:
                            # æ— æ•ˆäº¤æ˜“è®°å½•
                            continue
                        
                        transactions.append({
                            'date': transaction_date,
                            'description': description,
                            'amount': amount,
                            'type': transaction_type
                        })
            
            # å¦‚æœæ²¡æœ‰ä»æ–‡æœ¬ä¸­æå–åˆ°ï¼Œå°è¯•ä»è¡¨æ ¼æ•°æ®æå–
            if not transactions:
                print(f"âš ï¸ æ–‡æœ¬æå–å¤±è´¥ï¼Œå°è¯•è¡¨æ ¼æå–...")
                # ä»è¡¨æ ¼æ ¼å¼æå–
                table_pattern = r'(\d{4}-\d{2}-\d{2})\s*\|\s*(\d{4}-\d{2}-\d{2})\s*\|\s*(\d{4})\s*\|\s*(.*?)\s*\|\s*(\d+\.\d{2})?\s*\|\s*(\d+\.\d{2})?'
                table_matches = re.findall(table_pattern, pdf_content)
                
                print(f"ğŸ“Š è¡¨æ ¼åŒ¹é…åˆ° {len(table_matches)} æ¡è®°å½•")
                
                for i, match in enumerate(table_matches):
                    transaction_date = match[0]
                    description = match[3].strip()
                    deposit_amount = match[4]  # å­˜å…¥é‡‘é¢
                    expenditure_amount = match[5]  # æ”¯å‡ºé‡‘é¢
                    
                    # ç¡®å®šäº¤æ˜“ç±»å‹
                    if deposit_amount and deposit_amount != '0.00':
                        transaction_type = "å­˜å…¥"
                        amount = deposit_amount
                        print(f"ğŸ’° è¡¨æ ¼å­˜å…¥äº¤æ˜“ {i+1}: {transaction_date} {description} +{amount}")
                    elif expenditure_amount and expenditure_amount != '0.00':
                        transaction_type = "æ”¯å‡º"
                        amount = expenditure_amount
                        print(f"ğŸ’¸ è¡¨æ ¼æ”¯å‡ºäº¤æ˜“ {i+1}: {transaction_date} {description} -{amount}")
                    else:
                        continue
                    
                    transactions.append({
                        'date': transaction_date,
                        'description': description,
                        'amount': amount,
                        'type': transaction_type
                    })
            
            # æŒ‰æ—¥æœŸæ’åº
            transactions.sort(key=lambda x: x['date'], reverse=True)
            
            print(f"âœ… äº¤æ˜“æ˜ç»†æå–å®Œæˆ: å…± {len(transactions)} æ¡è®°å½•")
            for i, tx in enumerate(transactions, 1):
                print(f"   {i}. {tx['date']} {tx['type']} {tx['description']} {tx['amount']}")
            
        except Exception as e:
            print(f"âŒ æå–äº¤æ˜“æ˜ç»†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        return transactions

    def is_boc_credit_card_email(self, email_data):
        """æ£€æµ‹æ˜¯å¦æ˜¯ä¸­å›½é“¶è¡Œä¿¡ç”¨å¡é‚®ä»¶ - åŒ…å«è¯¦ç»†è¾“å‡º"""
        subject = email_data.get('subject', '').lower()
        from_email = email_data.get('from', '').lower()
        
      #  print(f"\nğŸ” æ£€æµ‹ä¸­å›½é“¶è¡Œä¿¡ç”¨å¡é‚®ä»¶:")
     #   print(f"   ä¸»é¢˜: {subject}")
       # print(f"   å‘ä»¶äºº: {from_email}")
        
        # æ£€æŸ¥ä¸»é¢˜æ˜¯å¦åŒ…å«å…³é”®è¯ï¼ˆæ‰©å±•å…³é”®è¯åˆ—è¡¨ï¼‰
        boc_keywords = [
            'ä¸­å›½é“¶è¡Œä¿¡ç”¨å¡', 'ä¸­è¡Œä¿¡ç”¨å¡'
        ]
        
        has_boc_subject = any(keyword in subject for keyword in boc_keywords)
        
        # æ£€æŸ¥å‘ä»¶äººæ˜¯å¦æ¥è‡ªä¸­å›½é“¶è¡Œï¼ˆæ‰©å±•åŸŸååˆ—è¡¨ï¼‰
        is_boc_sender = any(domain in from_email for domain in [
            'boc.cn', 'bankofchina.com', 'boczhangdan@bankofchina.com'
        ])
        
        result = has_boc_subject or is_boc_sender
     #   print(f"âœ… æ£€æµ‹ç»“æœ: {'æ˜¯ä¸­å›½é“¶è¡Œä¿¡ç”¨å¡é‚®ä»¶' if result else 'ä¸æ˜¯ä¸­å›½é“¶è¡Œä¿¡ç”¨å¡é‚®ä»¶'}")
      #  print(f"   ä¸»é¢˜åŒ¹é…: {has_boc_subject}, å‘ä»¶äººåŒ¹é…: {is_boc_sender}")
        
        return result

    def is_ccb_credit_card_email(self, email_data):
        """æ£€æµ‹æ˜¯å¦æ˜¯å»ºè®¾é“¶è¡Œä¿¡ç”¨å¡é‚®ä»¶"""
        subject = email_data.get('subject', '').lower()
        from_email = email_data.get('from', '').lower()
        
     #   print(f"\nğŸ” æ£€æµ‹å»ºè®¾é“¶è¡Œä¿¡ç”¨å¡é‚®ä»¶:")
     #   print(f"   ä¸»é¢˜: {subject}")
     #   print(f"   å‘ä»¶äºº: {from_email}")
        
        # æ£€æŸ¥ä¸»é¢˜æ˜¯å¦åŒ…å«å…³é”®è¯
        ccb_keywords = [
            'å»ºè®¾é“¶è¡Œä¿¡ç”¨å¡', 'å»ºè¡Œä¿¡ç”¨å¡', 'ccb credit card', 'ccbä¿¡ç”¨å¡'
        ]
        
        has_ccb_subject = any(keyword in subject for keyword in ccb_keywords)
        
        # æ£€æŸ¥å‘ä»¶äººæ˜¯å¦æ¥è‡ªå»ºè®¾é“¶è¡Œ
        is_ccb_sender = any(domain in from_email for domain in [
            'ccb.com', 'ccb.cn', 'å»ºè®¾é“¶è¡Œ', 'creditcard.ccb.com'
        ])
        
        result = has_ccb_subject or is_ccb_sender
     #   print(f"âœ… æ£€æµ‹ç»“æœ: {'æ˜¯å»ºè®¾é“¶è¡Œä¿¡ç”¨å¡é‚®ä»¶' if result else 'ä¸æ˜¯å»ºè®¾é“¶è¡Œä¿¡ç”¨å¡é‚®ä»¶'}")
      #  print(f"   ä¸»é¢˜åŒ¹é…: {has_ccb_subject}, å‘ä»¶äººåŒ¹é…: {is_ccb_sender}")
        
        return result

    def format_ccb_email_content(self, email_data, original_content):
        """æ ¼å¼åŒ–å»ºè®¾é“¶è¡Œé‚®ä»¶å†…å®¹ - æ·»åŠ ç»Ÿä¸€çš„å¤´éƒ¨ä¿¡æ¯"""
        print(f"\nğŸ¦ å¼€å§‹æ ¼å¼åŒ–å»ºè®¾é“¶è¡Œé‚®ä»¶å†…å®¹")
        
        subject = email_data['subject']
        from_ = email_data['from']
        
        # è§£æå‘ä»¶äººä¿¡æ¯
        from_name, from_email = self._parse_sender_info(from_)
        
        # æ„å»ºæ¶ˆæ¯å¤´ï¼ˆä¸å…¶ä»–é‚®ä»¶ä¿æŒä¸€è‡´ï¼‰
        message = ""
        
        # ç”¨æˆ·åï¼ˆç²—ä½“ï¼‰
        if from_name:
            message += f"**{from_name}**"
        
        # é‚®ç®±åœ°å€ï¼ˆç­‰å®½ï¼‰
        if from_email:
            if from_name:
                message += " "  # ç”¨æˆ·åå’Œé‚®ç®±ä¹‹é—´åŠ ç©ºæ ¼
            message += f"`{from_email}`"
        
        message += "\n"
        
        # ä¸»é¢˜ï¼ˆæ–œä½“ï¼‰
        if subject:
            message += f"_{subject}_\n\n"
        
        # å½»åº•æ¸…ç†ï¼Œåªä¿ç•™è´¦å•ä¸»ä½“å†…å®¹
        cleaned_content = self.extract_ccb_bill_content(original_content)
        message += cleaned_content
        
        print(f"âœ… å»ºè®¾é“¶è¡Œé‚®ä»¶æ ¼å¼åŒ–å®Œæˆï¼Œæ€»é•¿åº¦: {len(message)} å­—ç¬¦")
        
        return message

    def extract_ccb_bill_content(self, input_data):
        """æå–å»ºè®¾é“¶è¡Œè´¦å•ä¸»ä½“å†…å®¹ï¼Œç§»é™¤æ‰€æœ‰é‚®ä»¶å¤´éƒ¨ä¿¡æ¯"""
        if not input_data:
            return ""
        
        lines = input_data.split('\n')
        bill_lines = []
        in_bill_content = False
        
        # å…³é”®è¯æ ‡è¯†è´¦å•å†…å®¹å¼€å§‹
        bill_start_keywords = [
            'äº¤æ˜“æ—¥æœŸ', 'è®°è´¦æ—¥æœŸ', 'äººæ°‘å¸äº¤æ˜“æ˜ç»†', 
            'è´¦å•å‘¨æœŸ', 'å¡å·', 'ä¿¡ç”¨é¢åº¦'
        ]
        
        for line in lines:
            stripped_line = line.strip()
            
            # æ£€æµ‹è´¦å•å†…å®¹å¼€å§‹
            if not in_bill_content:
                if any(keyword in stripped_line for keyword in bill_start_keywords):
                    in_bill_content = True
                else:
                    continue  # è·³è¿‡å¤´éƒ¨ä¿¡æ¯
            
            # ä¸€æ—¦è¿›å…¥è´¦å•å†…å®¹åŒºåŸŸï¼Œå¼€å§‹æ”¶é›†
            if in_bill_content:
                if stripped_line:
                    bill_lines.append(stripped_line)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†çš„å…³é”®è¯ï¼Œè¿”å›åŸå§‹æ¸…ç†å†…å®¹
        if not bill_lines:
            return self.clean_ccb_bill_data(input_data)
        
        # å°†æ”¶é›†åˆ°çš„è´¦å•å†…å®¹åˆå¹¶å¹¶ç”¨ clean_ccb_bill_data æ¸…ç†
        bill_content = '\n'.join(bill_lines)
        return self.clean_ccb_bill_data(bill_content)

    def clean_ccb_bill_data(self, input_data):
        """æ¸…ç†å»ºè®¾é“¶è¡Œè´¦å•æ•°æ®ï¼Œåªå¤„ç†è¡¨æ ¼è¡Œ"""
        cleaned_lines = []
        for line in input_data.split('\n'):
            if not line.strip():
                cleaned_lines.append(line)
                continue
            
            # åªå¤„ç†çœ‹èµ·æ¥åƒè¡¨æ ¼æ•°æ®çš„è¡Œï¼ˆåŒ…å«å¤šä¸ªç©ºæ ¼åˆ†éš”çš„éƒ¨åˆ†ï¼‰
            # è·³è¿‡è¶…é“¾æ¥å’Œå…¶ä»–æ ¼å¼çš„è¡Œ
            if '   ' in line and not line.startswith('[') and '](' not in line:
                parts = [p.strip() for p in line.split('   ') if p.strip()]
                
                # ç§»é™¤ç¬¬äºŒä¸ªæ—¥æœŸï¼ˆç´¢å¼•ä¸º1çš„éƒ¨åˆ†ï¼‰
                if len(parts) > 1:
                    parts.pop(1)
                
                # æ£€æŸ¥å¹¶ç§»é™¤é‡å¤çš„è´§å¸é‡‘é¢
                currency_indices = [i for i, part in enumerate(parts) 
                                if part in ['CNY', 'USD', 'EUR', 'JPY']]
                
                if len(currency_indices) > 1:
                    first_currency_index = currency_indices[0]
                    currency = parts[first_currency_index]
                    
                    i = first_currency_index + 2
                    while i < len(parts):
                        if parts[i] == currency:
                            parts.pop(i)
                            if i < len(parts):
                                parts.pop(i)
                        else:
                            i += 1
                
                cleaned_line = '   '.join(parts)
                cleaned_lines.append(cleaned_line)
            else:
                # éè¡¨æ ¼è¡Œç›´æ¥ä¿ç•™
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)
    
    def extract_and_parse_pdf_attachments(self, msg):
        """æå–å¹¶è§£æPDFé™„ä»¶ - å¢å¼ºç‰ˆï¼ŒåŒ…å«å®Œæ•´ç»ˆç«¯è¾“å‡º"""
        pdf_content = ""
        pdf_found = False
        
        print("\n" + "="*80)
        print("ğŸ“„ å¼€å§‹æå–PDFé™„ä»¶")
        print("="*80)
        
        try:
            if msg.is_multipart():
                for part_num, part in enumerate(msg.walk(), 1):
                    content_type = part.get_content_type()
                    content_disposition = str(part.get("Content-Disposition", ""))
                    filename = part.get_filename() or ""
                    
                    print(f"\nğŸ” æ£€æŸ¥ç¬¬ {part_num} ä¸ªé‚®ä»¶éƒ¨åˆ†:")
                    print(f"   ğŸ“ å†…å®¹ç±»å‹: {content_type}")
                    print(f"   ğŸ“ å†…å®¹æè¿°: {content_disposition}")
                    print(f"   ğŸ“ æ–‡ä»¶å: {filename}")
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯PDFé™„ä»¶ï¼ˆæ”¾å®½æ¡ä»¶ï¼‰
                    is_pdf_attachment = (
                        content_type == "application/pdf" or 
                        filename.lower().endswith('.pdf')
                    )
                    
                    # æˆ–è€…æ˜¯å…¶ä»–å¯èƒ½åŒ…å«PDFçš„é™„ä»¶ç±»å‹
                    is_possible_pdf = (
                        "attachment" in content_disposition and 
                        (content_type in ["application/octet-stream", "application/x-pdf"] or
                        "pdf" in filename.lower())
                    )
                    
                    if is_pdf_attachment or is_possible_pdf:
                        print(f"âœ… æ‰¾åˆ°PDFé™„ä»¶: {filename}")
                        pdf_found = True
                        
                        # æå–PDFå†…å®¹
                        pdf_data = part.get_payload(decode=True)
                        if pdf_data:
                            print(f"ğŸ“Š PDFæ•°æ®å¤§å°: {len(pdf_data)} å­—èŠ‚")
                            print(f"ğŸ”„ å¼€å§‹è§£æPDFå†…å®¹...")
                            
                            content = self.parse_pdf_content(pdf_data)
                            if content:
                                print(f"âœ… PDFè§£ææˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                                pdf_content += f"\n\n**PDFæ–‡ä»¶: {filename}**\n\n{content}"
                                
                                # æ‰“å°å®Œæ•´çš„PDFå†…å®¹ï¼ˆä¸å†æˆªæ–­ï¼‰
                                print(f"\nğŸ“‹ PDFå®Œæ•´å†…å®¹:")
                                print("="*80)
                                print(content)
                                print("="*80)
                            else:
                                print(f"âŒ PDFè§£æå¤±è´¥æˆ–å†…å®¹ä¸ºç©º")
                                pdf_content += f"\n\n**PDFæ–‡ä»¶: {filename}**\n\nï¼ˆæ— æ³•è§£æå†…å®¹æˆ–å†…å®¹ä¸ºç©ºï¼‰"
                        else:
                            print(f"âŒ PDFé™„ä»¶ {filename} æ²¡æœ‰æ•°æ®")
                            pdf_content += f"\n\n**PDFæ–‡ä»¶: {filename}**\n\nï¼ˆé™„ä»¶æ•°æ®ä¸ºç©ºï¼‰"
                    else:
                        print(f"â­ï¸  è·³è¿‡éPDFéƒ¨åˆ†")
            
            if not pdf_found:
                print(f"âŒ åœ¨é‚®ä»¶ä¸­æœªæ‰¾åˆ°PDFé™„ä»¶")
            else:
                print(f"\nâœ… PDFé™„ä»¶å¤„ç†å®Œæˆï¼Œæ€»å†…å®¹é•¿åº¦: {len(pdf_content)} å­—ç¬¦")
                
            print("="*80)
            return pdf_content.strip()
        
        except Exception as e:
            print(f"âŒ è§£æPDFé™„ä»¶å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return ""
        
    def parse_pdf_content(self, pdf_data):
        """è§£æPDFæ–‡ä»¶å†…å®¹ - åŒ…å«è¯¦ç»†ç»ˆç«¯è¾“å‡º"""
        try:
            content = ""
            
            print(f"\nğŸ“– å¼€å§‹è§£æPDFæ•°æ® ({len(pdf_data)} å­—èŠ‚)")
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_file:
                temp_file.write(pdf_data)
                temp_file_path = temp_file.name
                print(f"ğŸ“ åˆ›å»ºä¸´æ—¶æ–‡ä»¶: {temp_file_path}")
            
            try:
                # ä½¿ç”¨pdfplumberè§£æPDF
                with pdfplumber.open(temp_file_path) as pdf:
                    total_pages = len(pdf.pages)
                    print(f"ğŸ“„ PDFæ€»é¡µæ•°: {total_pages}")
                    
                    for page_num, page in enumerate(pdf.pages, 1):
                        print(f"\nğŸ“„ è§£æç¬¬ {page_num}/{total_pages} é¡µ...")
                        
                        # æå–æ–‡æœ¬
                        text = page.extract_text()
                        if text:
                            print(f"ğŸ“ ç¬¬ {page_num} é¡µæ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
                            # æ¸…ç†æ–‡æœ¬
                            cleaned_text = self.clean_pdf_text(text)
                            if cleaned_text:
                                content += f"--- ç¬¬ {page_num} é¡µ ---\n{cleaned_text}\n\n"
                                # æ‰“å°å®Œæ•´çš„é¡µé¢å†…å®¹ï¼ˆä¸å†æˆªæ–­ï¼‰
                                print(f"ğŸ“‹ ç¬¬ {page_num} é¡µå®Œæ•´å†…å®¹:")
                                print("-" * 80)
                                print(cleaned_text)
                                print("-" * 80)
                            else:
                                print(f"âš ï¸  ç¬¬ {page_num} é¡µæ¸…ç†åå†…å®¹ä¸ºç©º")
                        else:
                            print(f"âš ï¸  ç¬¬ {page_num} é¡µæ— æ–‡æœ¬å†…å®¹")
                        
                        # æå–è¡¨æ ¼ï¼ˆå¦‚æœæœ‰ï¼‰
                        tables = page.extract_tables()
                        if tables:
                            print(f"ğŸ“Š ç¬¬ {page_num} é¡µå‘ç° {len(tables)} ä¸ªè¡¨æ ¼")
                            for table_num, table in enumerate(tables, 1):
                                if table and any(any(cell for cell in row) for row in table):
                                    table_text = self.format_table(table)
                                    if table_text:
                                        content += f"--- ç¬¬ {page_num} é¡µè¡¨æ ¼ {table_num} ---\n{table_text}\n\n"
                                        print(f"ğŸ“‹ è¡¨æ ¼ {table_num} å®Œæ•´å†…å®¹:")
                                        print("-" * 80)
                                        print(table_text)
                                        print("-" * 80)
                                    else:
                                        print(f"âš ï¸  è¡¨æ ¼ {table_num} æ ¼å¼åŒ–åä¸ºç©º")
                                else:
                                    print(f"âš ï¸  è¡¨æ ¼ {table_num} ä¸ºç©º")
                        else:
                            print(f"â„¹ï¸  ç¬¬ {page_num} é¡µæ— è¡¨æ ¼")
                    
                    print(f"\nâœ… PDFè§£æå®Œæˆï¼Œæ€»å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            
            finally:
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                import os
                os.unlink(temp_file_path)
                print(f"ğŸ—‘ï¸  åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_file_path}")
            
            return content.strip()
        
        except Exception as e:
            print(f"âŒ è§£æPDFå†…å®¹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return ""
    def clean_pdf_text(self, text):
        """æ¸…ç†PDFæå–çš„æ–‡æœ¬"""
        if not text:
            return ""
        
        # ç§»é™¤è¿‡å¤šçš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text)
        
        # ç§»é™¤é¡µçœ‰é¡µè„šç­‰å¸¸è§å™ªå£°
        lines = text.split('\n')
        cleaned_lines = []
        
        for line in lines:
            line = line.strip()
            # è·³è¿‡å¯èƒ½æ˜¯é¡µçœ‰é¡µè„šçš„è¡Œï¼ˆåŒ…å«é¡µç ã€æ—¥æœŸç­‰ï¼‰
            if (len(line) < 100 and 
                (re.match(r'^\d+$', line) or  # çº¯æ•°å­—ï¼ˆå¯èƒ½æ˜¯é¡µç ï¼‰
                re.match(r'^\d+/\d+$', line) or  # é¡µç æ ¼å¼ 1/10
                re.match(r'^\d{4}[-/]\d{1,2}[-/]\d{1,2}', line) or  # æ—¥æœŸ
                re.match(r'.*(é¡µ|ç¬¬.*é¡µ).*', line))):  # åŒ…å«"é¡µ"å­—
                continue
            
            if line and len(line) > 2:  # è·³è¿‡è¿‡çŸ­çš„è¡Œ
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)

    def format_table(self, table):
        """æ ¼å¼åŒ–è¡¨æ ¼æ•°æ® - æ˜¾ç¤ºå®Œæ•´å†…å®¹"""
        if not table:
            return ""
        
        formatted_lines = []
        
        for row_num, row in enumerate(table):
            # æ¸…ç†æ¯è¡Œçš„æ•°æ®
            cleaned_row = []
            for cell_num, cell in enumerate(row):
                cell_text = str(cell) if cell is not None else ""
                # ç§»é™¤è¿‡å¤šçš„ç©ºç™½
                cell_text = re.sub(r'\s+', ' ', cell_text).strip()
                cleaned_row.append(cell_text)
            
            # åªæ·»åŠ éç©ºè¡Œ
            if any(cleaned_row):
                formatted_line = " | ".join(cleaned_row)
                formatted_lines.append(formatted_line)
                print(f"   ç¬¬ {row_num+1} è¡Œ: {formatted_line}")
        
        result = "\n".join(formatted_lines) if formatted_lines else ""
        print(f"   è¡¨æ ¼æ€»è¡Œæ•°: {len(formatted_lines)}")
        
        return result

    def create_pdf_message(self, email_data, pdf_content):
        """åˆ›å»ºåŒ…å«PDFå†…å®¹çš„é‚®ä»¶æ¶ˆæ¯ - ä½¿ç”¨ç»Ÿä¸€å¤´éƒ¨æ ¼å¼"""
        subject = email_data['subject']
        from_ = email_data['from']
        
        # è§£æå‘ä»¶äººä¿¡æ¯
        from_name, from_email = self._parse_sender_info(from_)
        
        # æ„å»ºæ¶ˆæ¯å¤´ï¼ˆä¸å…¶ä»–é‚®ä»¶ä¿æŒä¸€è‡´ï¼‰
        message = ""
        
        # ç”¨æˆ·åï¼ˆç²—ä½“ï¼‰
        if from_name:
            message += f"**{from_name}**"
        
        # é‚®ç®±åœ°å€ï¼ˆç­‰å®½ï¼‰
        if from_email:
            if from_name:
                message += " "  # ç”¨æˆ·åå’Œé‚®ç®±ä¹‹é—´åŠ ç©ºæ ¼
            message += f"`{from_email}`"
        
        message += "\n"
        
        # ä¸»é¢˜ï¼ˆæ–œä½“ï¼‰
        if subject:
            message += f"_{subject}_\n\n"
        
        if pdf_content:
            # ä½¿ç”¨æ ¼å¼åŒ–å‡½æ•°å¤„ç†è´¦å•å†…å®¹
            formatted_content = self.format_boc_statement(pdf_content)
            message += formatted_content
        else:
            message += "**âŒ æœªæ‰¾åˆ°PDFé™„ä»¶å†…å®¹**\n"
            message += "é‚®ä»¶ä¸­å¯èƒ½ä¸åŒ…å«PDFé™„ä»¶ï¼Œæˆ–è€…é™„ä»¶æ ¼å¼ä¸æ”¯æŒã€‚"
        
        return message

    async def process_all_unread_emails_async(self):
        """å¼‚æ­¥å¤„ç†æ‰€æœ‰æœªè¯»é‚®ä»¶"""
   #     logging.info("å¼€å§‹æ£€æŸ¥æœªè¯»é‚®ä»¶...")
        
        # è¿æ¥é‚®ç®±
        mail = self.connect_email()
        if not mail:
            return False
        
        try:
            # è·å–æœªè¯»é‚®ä»¶
            email_ids = self.get_unread_emails(mail)
            if not email_ids:
            #    logging.info("æ²¡æœ‰æœªè¯»é‚®ä»¶éœ€è¦å¤„ç†")
                return True
            
            # å¤„ç†æ¯å°é‚®ä»¶
            success_count = 0
            for email_id in email_ids:
                if await self.process_single_email_async(mail, email_id):
                    success_count += 1
                
                # å¤„ç†é—´éš”ï¼Œé¿å…è¿‡å¿«
                await asyncio.sleep(2)
            
          #  logging.info(f"é‚®ä»¶å¤„ç†å®Œæˆ: æˆåŠŸ {success_count}/{len(email_ids)}")
            return success_count > 0
            
        except Exception as e:
            logging.error(f"å¤„ç†æœªè¯»é‚®ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
        finally:
            try:
                mail.close()
                mail.logout()
            except:
                pass

    def is_mainly_chinese(self, text):
        """æ£€æµ‹æ–‡æœ¬æ˜¯å¦ä¸»è¦æ˜¯ä¸­æ–‡"""
        if not text:
            return True
        
        # è®¡ç®—ä¸­æ–‡å­—ç¬¦çš„æ¯”ä¾‹
        chinese_pattern = re.compile(r'[\u4e00-\u9fff]')
        chinese_chars = len(chinese_pattern.findall(text))
        total_chars = len(text)
        
        # é¿å…é™¤é›¶é”™è¯¯
        if total_chars == 0:
            return True
        
        # å¦‚æœä¸­æ–‡å­—ç¬¦è¶…è¿‡10%çš„æ¯”ä¾‹ï¼Œåˆ™æ— éœ€ç¿»è¯‘
        return (chinese_chars / total_chars) > 0.1
    
    def translate_content_sync_safe(self, text):
        """å®‰å…¨ç¿»è¯‘ï¼Œæ”¯æŒé•¿æ–‡æœ¬åˆ†æ®µä¸”ä¿æŠ¤URL"""
        if not text or not ENABLE_TRANSLATION:
            return text
        
        # 1. å…ˆåˆ†å‰²URLå’Œçº¯æ–‡æœ¬
        segments = self.split_text_around_urls(text)
        final_segments = []
        
        for segment in segments:
            if self.contains_url_or_code(segment):
                # URLéƒ¨åˆ†ç›´æ¥ä¿ç•™
                final_segments.append(segment)
            else:
                # çº¯æ–‡æœ¬éƒ¨åˆ†éœ€è¦æ£€æŸ¥é•¿åº¦å¹¶å¯èƒ½åˆ†æ®µ
                if len(segment.encode('utf-8')) <= 1900:
                    # çŸ­æ–‡æœ¬ç›´æ¥ç¿»è¯‘
                    translated = self.translate_segment_safe(segment)
                    final_segments.append(translated)
                else:
                    # é•¿æ–‡æœ¬éœ€è¦è¿›ä¸€æ­¥åˆ†æ®µç¿»è¯‘
                    segmented_translation = self.translate_long_text_safe(segment)
                    final_segments.append(segmented_translation)
        
        return ''.join(final_segments)

    def translate_long_text_safe(self, long_text):
        """å®‰å…¨åœ°ç¿»è¯‘é•¿æ–‡æœ¬ï¼ˆåˆ†æ®µå¤„ç†ï¼‰"""
        # è¿™é‡Œå¯ä»¥å¤ç”¨ translate_content_sync() ä¸­çš„åˆ†æ®µé€»è¾‘
        # ä½†è¦ç¡®ä¿åªå¤„ç†çº¯æ–‡æœ¬ï¼Œä¸åŒ…å«URL
        MAX_BYTES = 1900
        segments = []
        current_segment = ""
        
        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = [p for p in long_text.split('\n\n') if p.strip()]
        
        for para in paragraphs:
            para_bytes = para.encode('utf-8')
            new_segment = current_segment + ("\n\n" + para if current_segment else para)
            
            if len(new_segment.encode('utf-8')) > MAX_BYTES:
                if current_segment:
                    # ç¿»è¯‘å·²ç§¯ç´¯çš„å†…å®¹
                    translated = self.translate_segment_safe(current_segment)
                    segments.append(translated)
                
                # å¤„ç†è¶…é•¿æ®µè½
                if len(para_bytes) > MAX_BYTES:
                    # æŒ‰å¥å­è¿›ä¸€æ­¥åˆ†å‰²
                    sentences = re.split(r'[ã€‚.!?ï¼Ÿ]\s*', para)
                    temp_segment = ""
                    for sentence in sentences:
                        if not sentence.strip():
                            continue
                        sentence_with_punct = sentence + "ã€‚"
                        if len((temp_segment + sentence_with_punct).encode('utf-8')) > MAX_BYTES:
                            if temp_segment:
                                translated = self.translate_segment_safe(temp_segment)
                                segments.append(translated)
                            temp_segment = sentence_with_punct
                        else:
                            temp_segment += sentence_with_punct
                    if temp_segment:
                        current_segment = temp_segment
                    else:
                        current_segment = ""
                else:
                    current_segment = para
            else:
                current_segment = new_segment
        
        # å¤„ç†æœ€åä¸€æ®µ
        if current_segment:
            translated = self.translate_segment_safe(current_segment)
            segments.append(translated)
        
        return "\n\n".join(segments)

    def split_text_around_urls(self, text):
        """å°†æ–‡æœ¬åˆ†å‰²ä¸ºURL/ä»£ç éƒ¨åˆ†å’Œçº¯æ–‡æœ¬éƒ¨åˆ†"""
        if not text:
            return [text]
        
        segments = []
        last_end = 0
        
        # åŒ¹é…æ‰€æœ‰éœ€è¦ä¿æŠ¤çš„æ¨¡å¼
        patterns = [
            r'`[^`]*`',  # ç­‰ä½“å­—
            r'\[[^\]]+\]\([^)]+\)',  # Markdowné“¾æ¥
            r'https?://[^\s<>"{}|\\^`\[\]()]+',  # çº¯URL
        ]
        
        # ç»„åˆæ‰€æœ‰æ¨¡å¼
        combined_pattern = '|'.join(patterns)
        
        for match in re.finditer(combined_pattern, text):
            # æ·»åŠ åŒ¹é…å‰çš„çº¯æ–‡æœ¬
            if match.start() > last_end:
                segments.append(text[last_end:match.start()])
            
            # æ·»åŠ åŒ¹é…çš„URL/ä»£ç ï¼ˆä¸ç¿»è¯‘ï¼‰
            segments.append(match.group(0))
            last_end = match.end()
        
        # æ·»åŠ å‰©ä½™æ–‡æœ¬
        if last_end < len(text):
            segments.append(text[last_end:])
        
        return segments

    def contains_url_or_code(self, text):
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«URLæˆ–ä»£ç """
        patterns = [
            r'`[^`]*`',
            r'\[[^\]]+\]\([^)]+\)', 
            r'https?://[^\s<>"{}|\\^`\[\]()]+',
            r'www\.[^\s<>"{}|\\^`\[\]()]+',
        ]
        
        for pattern in patterns:
            if re.search(pattern, text):
                return True
        return False

    def translate_segment_safe(self, text):
        """å®‰å…¨åœ°ç¿»è¯‘æ–‡æœ¬ç‰‡æ®µ"""
        if not text.strip():
            return text
        
        try:
            cred = credential.Credential(TENCENTCLOUD_SECRET_ID, TENCENTCLOUD_SECRET_KEY)
            http_profile = HttpProfile(endpoint="tmt.tencentcloudapi.com")
            client_profile = ClientProfile(httpProfile=http_profile)
            client = tmt_client.TmtClient(cred, TENCENT_REGION, client_profile)
            
            req = models.TextTranslateRequest()
            req.SourceText = text
            req.Source = "auto"
            req.Target = "zh"
            req.ProjectId = 0
            
            resp = client.TextTranslate(req)
            return resp.TargetText
            
        except Exception as e:
            logging.error(f"ç¿»è¯‘ç‰‡æ®µå¤±è´¥: {e}")
            return text  

async def main_async():
    """å¼‚æ­¥ä¸»å‡½æ•°"""
#   logging.info("=== é‚®ä»¶åˆ°Telegramè½¬å‘å™¨å¯åŠ¨ ===")
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = EmailToTelegramBot()
    
    # å¤„ç†æœªè¯»é‚®ä»¶
    success = await processor.process_all_unread_emails_async()
    
    if success:
        pass
    else:
        logging.error("=== å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ ===")
    
    return success

def main():
    """åŒæ­¥ä¸»å‡½æ•°ï¼Œä¿æŒå‘åå…¼å®¹"""
    return asyncio.run(main_async())

if __name__ == "__main__":
    main()