import asyncio
import aiohttp
import logging
import re
import os
import json
from pathlib import Path
from datetime import datetime
from feedparser import parse
from telegram import Bot
from telegram.error import BadRequest
from tencentcloud.common import credential
from tencentcloud.tmt.v20180321 import tmt_client, models

# 配置中心
load_dotenv()
BASE_DIR = Path(__file__).resolve().parent
STATUS_FILE = BASE_DIR / "rss.json"
MAX_CONCURRENT = 10
BOT_TOKENS = {
    'main': os.getenv("RSS_TWO"),
    'tech': os.getenv("RSS_TOKEN"),
}
CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "").split(",")[0]

# Feed组配置（新增类型只需在此添加）
FEED_GROUPS = {
    'translated': {
        'feeds': [
            'https://feeds.bbci.co.uk/news/world/rss.xml',
            'https://www3.nhk.or.jp/rss/news/cat6.xml',
        ],
        'bot': 'main',
        'translate': True,
        'preview': False
    },
    'simple': {
        'feeds': ['https://36kr.com/feed-newsflash'],
        'bot': 'main',
        'translate': False,
        'preview': True
    },
    'video': {
        'feeds': [
            'https://www.youtube.com/feeds/videos.xml?channel_id=UCvijahEyGtvMpmMHBu4FS2w',
            # ...其他视频源
        ],
        'bot': 'tech',
        'translate': False,
        'preview': True
    }
}

# 日志配置
logging.basicConfig(
    filename=BASE_DIR / "rss.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    encoding="utf-8"
)
logger = logging.getLogger(__name__)

class FeedProcessor:
    """通用Feed处理器（核心优化点1：合并重复逻辑）"""
    def __init__(self, config):
        self.translate = config['translate']
        self.disable_preview = not config['preview']
        self.bot = Bot(token=BOT_TOKENS[config['bot']])
        
        # 初始化腾讯翻译
        cred = credential.Credential(os.getenv("TENCENTCLOUD_SECRET_ID"), 
                                   os.getenv("TENCENTCLOUD_SECRET_KEY"))
        self.tmt_client = tmt_client.TmtClient(cred, "na-siliconvalley")

    async def process_group(self, session, feeds):
        """并行处理整个组（核心优化点2：并行处理）"""
        status = self.load_status()
        tasks = [self.process_feed(session, url, status) for url in feeds]
        results = await asyncio.gather(*tasks)
        
        # 批量发送消息（核心优化点3：合并网络请求）
        messages = [msg for msg in results if msg]
        if messages:
            await self.send_message("\n\n".join(messages))
        self.save_status(status)

    async def process_feed(self, session, url, status):
        """处理单个Feed"""
        try:
            feed = await self.fetch_feed(session, url)
            new_entries = self.get_new_entries(feed, status.get(url, {}))
            
            if not new_entries:
                return ""
                
            # 批量翻译（核心优化点4：减少API调用）
            translated = await self.batch_translate(new_entries)
            status[url] = self.get_latest_info(new_entries[-1])
            
            return self.format_message(feed.feed.title, translated)
        except Exception as e:
            logger.error(f"Process {url} failed: {str(e)}")
            return ""

    # 以下是工具方法（约减少60%重复代码）...
    @staticmethod
    def load_status():
        try:
            return json.loads(STATUS_FILE.read_text(encoding='utf-8'))
        except:
            return {}

    def save_status(self, status):
        STATUS_FILE.write_text(json.dumps(status), encoding='utf-8')

    async def fetch_feed(self, session):
        """带重试机制的获取"""
        for _ in range(3):
            try:
                async with session.get(url, timeout=30) as resp:
                    return parse(await resp.read())
            except Exception as e:
                logger.warning(f"Retrying {url} due to {str(e)}")
                await asyncio.sleep(2)
        return None

    def get_new_entries(self, feed, last_status):
        """智能检测新条目"""
        if not feed or not feed.entries:
            return []
            
        # 使用混合校验（时间戳+ID）
        last_id = last_status.get('id')
        last_time = datetime.fromisoformat(last_status.get('time', '1970-01-01'))
        
        return [entry for entry in feed.entries
               if (datetime(*entry.published_parsed[:6]) > last_time or
                   getattr(entry, 'id', None) != last_id)]

    async def batch_translate(self, entries):
        """批量翻译优化"""
        if not self.translate:
            return entries
            
        texts = [f"{e.title}\n{e.summary}" for e in entries]
        req = models.TextTranslateBatchRequest()
        req.SourceTextList = texts
        req.Source = "auto"
        req.Target = "zh"
        
        try:
            res = self.tmt_client.TextTranslateBatch(req)
            return res.TargetTextList
        except Exception as e:
            logger.error(f"Translation failed: {str(e)}")
            return texts

    def format_message(self, title, contents):
        """统一消息格式化"""
        header = f"**{self.escape(title)}**\n\n"
        body = "\n\n".join(
            f"• {self.escape(content[:200])}\n{getattr(entry, 'link', '')}"
            for content, entry in zip(contents, entries)
        )
        return header + body + f"\n\n✅ 新增 {len(contents)} 条"

    @staticmethod
    def escape(text):
        """增强的Markdown转义"""
        return re.sub(r'([_*\[\]()~`>#+-=|{}.!])', r'\\\1', text)

    async def send_message(self, text):
        """智能分块发送"""
        chunks = [text[i:i+4096] for i in range(0, len(text), 4096)]
        for chunk in chunks:
            await self.bot.send_message(
                chat_id=CHAT_ID,
                text=chunk,
                parse_mode='MarkdownV2',
                disable_web_page_preview=self.disable_preview
            )

async def main():
    async with aiohttp.ClientSession() as session:
        # 并行处理所有组（核心优化点5：整体并行）
        await asyncio.gather(*[
            FeedProcessor(cfg).process_group(session, grp['feeds'])
            for grp_name, grp in FEED_GROUPS.items()
        ])

if __name__ == "__main__":
    asyncio.run(main())